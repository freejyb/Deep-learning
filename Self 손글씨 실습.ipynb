{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d1312f-1c88-4970-bd09-a7c1070b3004",
   "metadata": {},
   "source": [
    "# 1. Self 손글씨 맞추기 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada80337-f09c-44e9-b101-010e760e54c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ef2be94-119c-4b68-9d88-42992c142a27",
   "metadata": {},
   "source": [
    "MNIST 데이터셋을 사용해 학습된 인공신경망을 이용해 사용자가 제공한 숫자 이미지를 예측하는 코드를 작성해보겠습니다. \n",
    "\n",
    "MNIST 데이터셋은 손으로 쓴 숫자(0-9) 이미지들로 구성된 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb74f09-f42b-4be0-9817-87881f68868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JYB\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.8576 - loss: 0.4543 - val_accuracy: 0.9851 - val_loss: 0.0463\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9820 - loss: 0.0549 - val_accuracy: 0.9894 - val_loss: 0.0296\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - accuracy: 0.9896 - loss: 0.0337 - val_accuracy: 0.9888 - val_loss: 0.0327\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.9908 - loss: 0.0283 - val_accuracy: 0.9881 - val_loss: 0.0379\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9927 - loss: 0.0239 - val_accuracy: 0.9892 - val_loss: 0.0338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "예측된 숫자: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image  # 사용자가 제공한 이미지를 처리하기 위해 사용\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 데이터 전처리\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# 간단한 CNN 모델 생성\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# 사용자 이미지 예측 함수 정의\n",
    "def predict_image(image_path):\n",
    "    # 이미지 로드 및 전처리\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "    img = np.array(img).astype('float32') / 255\n",
    "    img = 1 - img  # 흑백 반전 (흰 배경에 검은 숫자로 맞추기 위해)\n",
    "    img = img.reshape((1, 28, 28, 1))\n",
    "    \n",
    "    # 예측\n",
    "    prediction = model.predict(img)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    print(f\"예측된 숫자: {predicted_label}\")\n",
    "\n",
    "# 테스트할 사용자 이미지 경로\n",
    "image_path = 'KakaoTalk_20241124_215514801.jpg'  # 여기서 'your_image.png'를 예측할 이미지 파일 경로로 변경하세요\n",
    "predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c78a2-c3b7-45c3-a29a-3e42c2ecdeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85bcfb8-585e-4b0f-b9b9-3eed7972905e",
   "metadata": {},
   "source": [
    "손글씨 코드설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a48ee-5bbf-4769-a394-73a76a700be5",
   "metadata": {},
   "source": [
    "#### 1)  라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04f8a5-5306-492b-b554-aa229d6df8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "# from tensorflow.keras.datasets import mnist\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d418c1e8-9305-4ecf-b9b9-48e1753c88c9",
   "metadata": {},
   "source": [
    "#### 2) MNIST 데이터셋 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aca481-411f-4a23-842b-8c3ad93d356b",
   "metadata": {},
   "source": [
    "MNIST 데이터셋은 손으로 쓴 숫자 이미지 (0-9)로 구성되어 있으며, Keras에서 쉽게 로드할 수 있습니다.\n",
    "\n",
    "(train_images, train_labels)는 학습용 데이터, (test_images, test_labels)는 테스트용 데이터를 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbff70c-a070-4326-b806-769cd0ad2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce845437-163b-4474-aae3-61f204c15a9f",
   "metadata": {},
   "source": [
    "#### 3) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453efbaa-d104-4c96-a3ff-1609301ccdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "# test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)\n",
    "# 이미지를 (28, 28, 1)의 형태로 변형하고, float32 타입으로 변환하여 정규화(/ 255)합니다. 이는 픽셀 값을 0~1 사이로 맞추기 위함입니다.\n",
    "# to_categorical() 함수는 레이블을 원-핫 인코딩으로 변환하여, 분류 문제에 적합하게 만들어줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50336c-4bb2-4d1c-947a-c872c91bf929",
   "metadata": {},
   "source": [
    "#### 4) CNN 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8377730-8f31-4e08-8cf4-098bb1929a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Sequential 모델을 사용해 신경망을 구성합니다.\n",
    "# Conv2D 층은 필터 크기가 (3, 3)인 컨볼루션 연산을 통해 이미지 특징을 추출합니다.\n",
    "# MaxPooling2D는 풀링 연산을 통해 이미지 크기를 줄여 계산 효율성을 높입니다.\n",
    "# Flatten()은 다차원 배열을 1차원으로 변환합니다.\n",
    "# Dense 층은 완전 연결 계층으로, 마지막 층에서는 10개의 클래스(숫자 0-9)에 대한 확률을 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50c1a6-149a-4acf-8c35-e56249a35e30",
   "metadata": {},
   "source": [
    "#### 5) 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1f84e-7880-4475-a2c6-1af922f69321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# adam 옵티마이저를 사용해 모델을 컴파일합니다.\n",
    "# 손실 함수로는 categorical_crossentropy를 사용하며, 이는 다중 클래스 분류에 적합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a04d7-7360-476b-83da-4c10d894167b",
   "metadata": {},
   "source": [
    "#### 6) 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726955e-b2ac-4f2c-8ab3-90103faf465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# fit() 함수를 통해 모델을 학습시킵니다.\n",
    "# 에포크 수는 5회, 배치 크기는 64로 설정하였습니다. validation_data는 학습 동안 모델의 성능을 평가하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef622562-fa07-4f32-aeb9-beeb081825a0",
   "metadata": {},
   "source": [
    "#### 7) 사용자 이미지 예측 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9d55a-fbd7-4cfd-9624-866fd4993dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_image(image_path):\n",
    "#     # 이미지 로드 및 전처리\n",
    "#     img = Image.open(image_path).convert('L')\n",
    "#     img = img.resize((28, 28))\n",
    "#     img = np.array(img).astype('float32') / 255\n",
    "#     img = 1 - img  # 흑백 반전 (흰 배경에 검은 숫자로 맞추기 위해)\n",
    "#     img = img.reshape((1, 28, 28, 1))\n",
    "    \n",
    "#     # 예측\n",
    "#     prediction = model.predict(img)\n",
    "#     predicted_label = np.argmax(prediction)\n",
    "#     print(f\"예측된 숫자: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341c377-42cd-4e73-b940-d79783131cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_image() 함수는 사용자가 제공한 이미지를 모델에 입력하여 예측합니다.\n",
    "# 이미지를 회색조(L)로 변환하고 (28, 28) 크기로 조정합니다.\n",
    "# 1 - img를 통해 흑백을 반전하여 MNIST 데이터와 유사한 형식으로 만듭니다.\n",
    "# 모델의 predict() 함수를 사용해 이미지를 예측하고, argmax()로 가장 높은 확률의 클래스를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec36cb-0680-4394-93a4-d65bd90fc4b0",
   "metadata": {},
   "source": [
    "#### 8) 이미지 경로 설정 및 예측 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee0444f-c5ba-4f64-bd5e-f828cefe0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'your_image.png'  # 여기서 'your_image.png'를 예측할 이미지 파일 경로로 변경하세요\n",
    "# predict_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d84a90-6edf-4cb0-80e1-ab0d64ff6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'your_image.png'를 사용자가 예측하고자 하는 이미지 파일 경로로 변경한 후, predict_image() 함수를 호출해 예측 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821aaf3-cb42-4f68-9219-81197e60c935",
   "metadata": {},
   "source": [
    "# 2. 0부터 9까지의 확률로 보여주가 : epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "301d5efc-f01b-45f6-8a6b-645e1e0b9eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - accuracy: 0.8721 - loss: 0.4100 - val_accuracy: 0.9796 - val_loss: 0.0604\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9825 - loss: 0.0559 - val_accuracy: 0.9877 - val_loss: 0.0405\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.9884 - loss: 0.0366 - val_accuracy: 0.9872 - val_loss: 0.0419\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9917 - loss: 0.0268 - val_accuracy: 0.9902 - val_loss: 0.0309\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9937 - loss: 0.0205 - val_accuracy: 0.9893 - val_loss: 0.0341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "예측된 숫자: 7\n",
      "0부터 9까지의 확률:\n",
      "0: 7.08%\n",
      "1: 13.14%\n",
      "2: 10.42%\n",
      "3: 6.38%\n",
      "4: 8.49%\n",
      "5: 9.13%\n",
      "6: 5.68%\n",
      "7: 30.87%\n",
      "8: 3.04%\n",
      "9: 5.75%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 데이터 전처리\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# 간단한 CNN 모델 생성\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# 사용자 이미지 예측 함수 정의\n",
    "def predict_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: 파일을 찾을 수 없습니다. 경로를 확인해주세요: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "    img = np.array(img).astype('float32') / 255\n",
    "    img = 1 - img  # 흑백 반전 (흰 배경에 검은 숫자로 맞추기 위해)\n",
    "    img = img.reshape((1, 28, 28, 1))\n",
    "    \n",
    "    # 예측\n",
    "    prediction = model.predict(img)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    print(f\"예측된 숫자: {predicted_label}\")\n",
    "    print(\"0부터 9까지의 확률:\")\n",
    "    for i, prob in enumerate(prediction[0]):\n",
    "        print(f\"{i}: {prob * 100:.2f}%\")\n",
    "\n",
    "# 테스트할 사용자 이미지 경로\n",
    "image_path = 'KakaoTalk_20241124_215514801.jpg'  # 여기서 'your_image.png'를 예측할 이미지 파일 경로로 변경하세요\n",
    "predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f547888-77d7-45c8-8254-aaaac56754ed",
   "metadata": {},
   "source": [
    "# 3. 0부터 9까지의 확률로 보여주가 : epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f29b371-ce76-4310-8836-607f8076cc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.8649 - loss: 0.4329 - val_accuracy: 0.9844 - val_loss: 0.0441\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 16ms/step - accuracy: 0.9826 - loss: 0.0560 - val_accuracy: 0.9876 - val_loss: 0.0429\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.9878 - loss: 0.0398 - val_accuracy: 0.9879 - val_loss: 0.0349\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 0.9896 - val_loss: 0.0308\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9936 - loss: 0.0210 - val_accuracy: 0.9910 - val_loss: 0.0293\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9942 - loss: 0.0177 - val_accuracy: 0.9913 - val_loss: 0.0273\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9948 - loss: 0.0161 - val_accuracy: 0.9898 - val_loss: 0.0314\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9959 - loss: 0.0129 - val_accuracy: 0.9917 - val_loss: 0.0313\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9928 - val_loss: 0.0262\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9935 - val_loss: 0.0268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "예측된 숫자: 5\n",
      "0부터 9까지의 확률:\n",
      "0: 8.57%\n",
      "1: 11.59%\n",
      "2: 12.49%\n",
      "3: 7.46%\n",
      "4: 5.25%\n",
      "5: 21.14%\n",
      "6: 4.07%\n",
      "7: 21.06%\n",
      "8: 4.75%\n",
      "9: 3.62%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 데이터 전처리\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# 간단한 CNN 모델 생성\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# 사용자 이미지 예측 함수 정의\n",
    "def predict_image(image_path):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: 파일을 찾을 수 없습니다. 경로를 확인해주세요: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    img = Image.open(image_path).convert('L')\n",
    "    img = img.resize((28, 28))\n",
    "    img = np.array(img).astype('float32') / 255\n",
    "    img = 1 - img  # 흑백 반전 (흰 배경에 검은 숫자로 맞추기 위해)\n",
    "    img = img.reshape((1, 28, 28, 1))\n",
    "    \n",
    "    # 예측\n",
    "    prediction = model.predict(img)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    print(f\"예측된 숫자: {predicted_label}\")\n",
    "    print(\"0부터 9까지의 확률:\")\n",
    "    for i, prob in enumerate(prediction[0]):\n",
    "        print(f\"{i}: {prob * 100:.2f}%\")\n",
    "\n",
    "# 테스트할 사용자 이미지 경로\n",
    "image_path = 'KakaoTalk_20241124_215514801.jpg'  # 여기서 'your_image.png'를 예측할 이미지 파일 경로로 변경하세요\n",
    "predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2e8d98-1678-476f-88a9-eb370ed33ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
