{"cells":[{"cell_type":"markdown","id":"d67e6397","metadata":{"id":"d67e6397"},"source":["2017년에 구글에서 발표한 \"Attention is All You Need\" 논문에서는 Transformer 모델이 제안"]},{"cell_type":"markdown","id":"689f1096","metadata":{"id":"689f1096"},"source":["Transformer 모델은 어텐션 메커니즘을 기반으로 하여, 기존의 RNN이나 LSTM을 대체하는 순차 처리 대신 병렬 처리를 가능하게 했습니다.\n","\n","특히 Self-Attention과 Multi-Head Attention 메커니즘이 핵심입니다."]},{"cell_type":"markdown","id":"5528ea5f","metadata":{"id":"5528ea5f"},"source":[" Transformer 모델 구현 코드 (구글 어텐션 논문 구현)"]},{"cell_type":"markdown","id":"1b829fa5","metadata":{"id":"1b829fa5"},"source":["[트랜스포머는 크게 다음과 같은 주요 구성 요소]\n","\n","입력 임베딩(Input Embedding): 입력 토큰을 고차원 벡터로 변환.\n","\n","포지셔널 인코딩(Positional Encoding): 위치 정보를 입력 벡터에 추가.\n","\n","인코더 블록(Encoder Block): Self-Attention과 피드포워드 층을 포함하는 인코더.\n","\n","디코더 블록(Decoder Block): Masked Multi-Head Attention과 피드포워드 층을 포함하는 디코더\n","\n",".\n","출력층(Output Layer): 예측된 토큰을 확률로 변환하는 소프트맥스 층."]},{"cell_type":"code","execution_count":null,"id":"0fdaa78e","metadata":{"id":"0fdaa78e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"d9b7fec5","metadata":{"id":"d9b7fec5"},"source":["# 영어를 한국어로"]},{"cell_type":"code","execution_count":null,"id":"08233d8f","metadata":{"id":"08233d8f"},"outputs":[],"source":["# i am a student"]},{"cell_type":"markdown","id":"6bdc540f","metadata":{"id":"6bdc540f"},"source":["## 사전학습된 경우가 아닌 경우"]},{"cell_type":"code","execution_count":null,"id":"b7fc86b4","metadata":{"id":"b7fc86b4"},"outputs":[],"source":["# Transformer 모델을 직접 구현하기 위해서는 기본적으로 TensorFlow 또는 PyTorch 같은 딥러닝 프레임워크를 사용해야 하며, 기본적인 Transformer 구조를 정의해야 합니다.\n","# 여기서는 TensorFlow를 사용하여 Transformer 모델을 직접 구성하는 예제를 보여드리겠습니다."]},{"cell_type":"code","execution_count":null,"id":"710c6b17","metadata":{"id":"710c6b17"},"outputs":[],"source":["# 1. Transformer 모델 구현 개요\n","# Transformer는 인코더와 디코더로 구성된 자연어 처리(NLP) 모델입니다. 번역 작업에서, 인코더는 입력 문장을 처리하고, 디코더는 번역된 결과 문장을 생성합니다. 우리는 직접 데이터를 준비해 Transformer 모델을 훈련시키고 영어 문장을 한국어로 번역할 수 있습니다.\n","\n","# 이 코드 예제는 Transformer 모델을 직접 정의하여 사용하는 과정 중 일부만을 다룹니다.\n","# 실제로 이 모델을 학습하려면 많은 데이터와 연산 자원이 필요하지만, 여기서는 간단한 Transformer 모델 구조를 보여드립니다."]},{"cell_type":"code","execution_count":4,"id":"1a73317e","metadata":{"id":"1a73317e","executionInfo":{"status":"ok","timestamp":1729749831819,"user_tz":-540,"elapsed":294,"user":{"displayName":"전윤범","userId":"16579588953913211126"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n","from tensorflow.keras import Model\n","\n","# Multi-head Attention Layer\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n","\n","        if mask is not None:\n","            scaled_attention_logits += (mask * -1e9)\n","\n","        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","        output = tf.matmul(attention_weights, v)\n","        output = tf.transpose(output, perm=[0, 2, 1, 3])\n","        output = tf.reshape(output, (batch_size, -1, self.d_model))\n","        return self.dense(output)\n","\n","# Transformer Encoder Layer\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = tf.keras.Sequential([Dense(dff, activation='relu'), Dense(d_model)])\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(dropout_rate)\n","        self.dropout2 = Dropout(dropout_rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","# 전체 Transformer 모델 구현 (간단히 인코더만 포함)\n","class Transformer(Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, max_pos_encoding, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","        self.embedding = Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = self.positional_encoding(max_pos_encoding, d_model)\n","        self.dropout = Dropout(dropout_rate)\n","        self.final_layer = Dense(target_vocab_size)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","\n","        for encoder_layer in self.encoder_layers:\n","            x = encoder_layer(x, training, mask)\n","\n","        return self.final_layer(x)\n"]},{"cell_type":"code","execution_count":14,"id":"6917f270","metadata":{"id":"6917f270","executionInfo":{"status":"ok","timestamp":1729750534942,"user_tz":-540,"elapsed":331,"user":{"displayName":"전윤범","userId":"16579588953913211126"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n","from tensorflow.keras import Model\n","\n","# Multi-head Attention Layer\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n","\n","        if mask is not None:\n","            scaled_attention_logits += (mask * -1e9)\n","\n","        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","        output = tf.matmul(attention_weights, v)\n","        output = tf.transpose(output, perm=[0, 2, 1, 3])\n","        output = tf.reshape(output, (batch_size, -1, self.d_model))\n","        return self.dense(output)\n","\n","# Transformer Encoder Layer\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = tf.keras.Sequential([Dense(dff, activation='relu'), Dense(d_model)])\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(dropout_rate)\n","        self.dropout2 = Dropout(dropout_rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","# 전체 Transformer 모델 구현 (간단히 인코더만 포함)\n","class Transformer(Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, max_pos_encoding, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","        self.embedding = Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = self.positional_encoding(max_pos_encoding, d_model)\n","        self.dropout = Dropout(dropout_rate)\n","        self.final_layer = Dense(target_vocab_size)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","\n","        for encoder_layer in self.encoder_layers:\n","            x = encoder_layer(x, training, mask)\n","\n","        return self.final_layer(x)\n","\n","\n","# Multi-head Attention Layer (이미 구현된 부분)\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n","\n","        if mask is not None:\n","            scaled_attention_logits += (mask * -1e9)\n","\n","        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","        output = tf.matmul(attention_weights, v)\n","        output = tf.transpose(output, perm=[0, 2, 1, 3])\n","        output = tf.reshape(output, (batch_size, -1, self.d_model))\n","        return self.dense(output)\n","\n","# 디코더 레이어\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)  # Self-attention\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)  # Enc-Dec attention\n","\n","        self.ffn = tf.keras.Sequential([Dense(dff, activation='relu'), Dense(d_model)])\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(dropout_rate)\n","        self.dropout2 = Dropout(dropout_rate)\n","        self.dropout3 = Dropout(dropout_rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        attn1 = self.mha1(x, x, x, look_ahead_mask)  # Self-attention\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        attn2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # Enc-Dec attention\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","\n","        ffn_output = self.ffn(out2)  # Feed forward network\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","\n","        return out3\n","\n","# 전체 Transformer 모델\n","class Transformer(Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, max_pos_encoding, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","\n","        self.embedding = Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = self.positional_encoding(max_pos_encoding, d_model)\n","        self.dropout = Dropout(dropout_rate)\n","        self.final_layer = Dense(target_vocab_size)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        # 인코더 처리\n","        enc_output = inp\n","        for encoder_layer in self.encoder_layers:\n","            enc_output = encoder_layer(enc_output, training, enc_padding_mask)\n","\n","        # 디코더 처리\n","        dec_output = tar\n","        for decoder_layer in self.decoder_layers:\n","            dec_output = decoder_layer(dec_output, enc_output, training, look_ahead_mask, dec_padding_mask)\n","\n","        # 최종 출력\n","        final_output = self.final_layer(dec_output)\n","        return final_output\n","\n"]},{"cell_type":"code","source":["# 가상 데이터 예시\n","import numpy as np\n","\n","# 입력 데이터\n","sample_input = np.array([[1, 2, 3, 4]])  # \"I am a student\"에 해당하는 인덱스\n","sample_target = np.array([[5, 6, 7, 8]])  # \"나는 학생입니다\"에 해당하는 인덱스\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n","from tensorflow.keras import Model\n","\n","class Transformer(Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, max_pos_encoding, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        # 인코더와 디코더 레이어 생성\n","        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","\n","        self.embedding = Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = self.positional_encoding(max_pos_encoding, d_model)\n","        self.dropout = Dropout(dropout_rate)\n","        self.final_layer = Dense(target_vocab_size)\n","\n","    def get_angles(self, pos, i, d_model):\n","        \"\"\"\n","        포지셔널 인코딩을 위한 각도 계산 함수\n","        pos: 각 단어의 위치\n","        i: 임베딩 벡터의 차원\n","        d_model: 모델의 임베딩 차원\n","        \"\"\"\n","        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","        return pos * angle_rates\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # 짝수 인덱스에 대해 사인 적용\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # 홀수 인덱스에 대해 코사인 적용\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        # 인코더 처리\n","        enc_output = inp\n","        for encoder_layer in self.encoder_layers:\n","            enc_output = encoder_layer(enc_output, training, enc_padding_mask)\n","\n","        # 디코더 처리\n","        dec_output = tar\n","        for decoder_layer in self.decoder_layers:\n","            dec_output = decoder_layer(dec_output, enc_output, training, look_ahead_mask, dec_padding_mask)\n","\n","        # 최종 출력\n","        final_output = self.final_layer(dec_output)\n","        return final_output\n","\n","\n","# Transformer 모델 생성\n","sample_transformer = Transformer(\n","    num_layers=2,\n","    d_model=512,\n","    num_heads=8,\n","    dff=2048,\n","    input_vocab_size=10000,\n","    target_vocab_size=10000,\n","    max_pos_encoding=5000\n",")\n","\n","# Transformer 모델 생성 후 호출할 때\n","output = sample_transformer(\n","    inp=sample_input,              # 입력 인자\n","    tar=sample_target,             # 타겟 인자\n","    training=False,                # training을 명시적인 키워드 인자로 전달\n","    enc_padding_mask=None,         # 패딩 마스크\n","    look_ahead_mask=None,          # look-ahead 마스크\n","    dec_padding_mask=None          # 디코더 패딩 마스크\n",")\n","\n","\n","# 모델을 통해 번역 결과 생성\n","output = sample_transformer(\n","    inp=sample_input,\n","    tar=sample_target,\n","    training=False,\n","    enc_padding_mask=None,\n","    look_ahead_mask=None,\n","    dec_padding_mask=None\n",")\n","\n","print(\"번역된 결과:\", output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549},"id":"MPShZnRrKxbE","executionInfo":{"status":"error","timestamp":1729750754064,"user_tz":-540,"elapsed":697,"user":{"displayName":"전윤범","userId":"16579588953913211126"}},"outputId":"3f65d430-a79b-454f-d7f9-247fa38e34c3"},"id":"MPShZnRrKxbE","execution_count":18,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Exception encountered when calling Transformer.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Transformer.call():\n  • inp=tf.Tensor(shape=(1, 4), dtype=int64)\n  • tar=tf.Tensor(shape=(1, 4), dtype=int64)\n  • training=False\n  • enc_padding_mask=None\n  • look_ahead_mask=None\n  • dec_padding_mask=None","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-24923e773723>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Transformer 모델 생성 후 호출할 때\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m output = sample_transformer(\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m# 입력 인자\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_target\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# 타겟 인자\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-24923e773723>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mencoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# 디코더 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Transformer.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Transformer.call():\n  • inp=tf.Tensor(shape=(1, 4), dtype=int64)\n  • tar=tf.Tensor(shape=(1, 4), dtype=int64)\n  • training=False\n  • enc_padding_mask=None\n  • look_ahead_mask=None\n  • dec_padding_mask=None"]}]},{"cell_type":"code","source":["# 디코드 과정"],"metadata":{"id":"d-SgXiWdI_HI","executionInfo":{"status":"ok","timestamp":1729750162653,"user_tz":-540,"elapsed":319,"user":{"displayName":"전윤범","userId":"16579588953913211126"}}},"id":"d-SgXiWdI_HI","execution_count":9,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n","from tensorflow.keras import Model\n","\n","# Multi-head Attention Layer (이미 구현된 부분)\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n","\n","        if mask is not None:\n","            scaled_attention_logits += (mask * -1e9)\n","\n","        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","        output = tf.matmul(attention_weights, v)\n","        output = tf.transpose(output, perm=[0, 2, 1, 3])\n","        output = tf.reshape(output, (batch_size, -1, self.d_model))\n","        return self.dense(output)\n","\n","# 디코더 레이어\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)  # Self-attention\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)  # Enc-Dec attention\n","\n","        self.ffn = tf.keras.Sequential([Dense(dff, activation='relu'), Dense(d_model)])\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(dropout_rate)\n","        self.dropout2 = Dropout(dropout_rate)\n","        self.dropout3 = Dropout(dropout_rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        attn1 = self.mha1(x, x, x, look_ahead_mask)  # Self-attention\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        attn2 = self.mha2(enc_output, enc_output, out1, padding_mask)  # Enc-Dec attention\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","\n","        ffn_output = self.ffn(out2)  # Feed forward network\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","\n","        return out3\n","\n","# 전체 Transformer 모델\n","class Transformer(Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, max_pos_encoding, dropout_rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","        self.decoder_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n","\n","        self.embedding = Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = self.positional_encoding(max_pos_encoding, d_model)\n","        self.dropout = Dropout(dropout_rate)\n","        self.final_layer = Dense(target_vocab_size)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","        # 인코더 처리\n","        enc_output = inp\n","        for encoder_layer in self.encoder_layers:\n","            enc_output = encoder_layer(enc_output, training, enc_padding_mask)\n","\n","        # 디코더 처리\n","        dec_output = tar\n","        for decoder_layer in self.decoder_layers:\n","            dec_output = decoder_layer(dec_output, enc_output, training, look_ahead_mask, dec_padding_mask)\n","\n","        # 최종 출력\n","        final_output = self.final_layer(dec_output)\n","        return final_output\n"],"metadata":{"id":"A0vfzp-LI_5a","executionInfo":{"status":"ok","timestamp":1729750139863,"user_tz":-540,"elapsed":332,"user":{"displayName":"전윤범","userId":"16579588953913211126"}}},"id":"A0vfzp-LI_5a","execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BBZ6IM4hJdeR"},"id":"BBZ6IM4hJdeR","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"osnOJwxSJdic"},"id":"osnOJwxSJdic","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pLkazZ0uJdl7"},"id":"pLkazZ0uJdl7","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s2oNgREyJdpl"},"id":"s2oNgREyJdpl","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"80d38fcb","metadata":{"id":"80d38fcb"},"source":["## 사전학습모델 소개(작동 문제)"]},{"cell_type":"code","source":[],"metadata":{"id":"Uv3E8UDmJcZ-"},"id":"Uv3E8UDmJcZ-","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6jc--2k6Jcec"},"id":"6jc--2k6Jcec","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"df0ddc5f","metadata":{"id":"df0ddc5f"},"outputs":[],"source":["# Transformer 모델을 이용하여 \"I am a student\" 문장을 한국어로 번역하는 코드를 구현하려면,\n","# 사전 학습된 Transformer 기반 번역 모델(예: Hugging Face의 transformers 라이브러리에서 제공하는 MarianMT 모델)을 사용할 수 있습니다. 이 모델은 다양한 언어 간 번역 작업을 쉽게 수행할 수 있도록 지원합니다.\n","# 여기서는 Hugging Face의 transformers 라이브러리를 사용하여 영어-한국어 번역을 하는 Transformer 모델 예시 코드를 보여드리겠습니다."]},{"cell_type":"code","execution_count":null,"id":"688c84e0","metadata":{"id":"688c84e0"},"outputs":[],"source":["# Hugging Face는 **자연어 처리(NLP)**와 머신러닝을 위한 오픈소스 도구와 라이브러리를 제공하는 AI 연구 및 개발 회사입니다. 특히 Transformer 모델과 관련된 연구와 도구 개발에 큰 기여를 하고 있습니다. Hugging Face의 대표적인 제품 중 하나는 transformers 라이브러리로, 다양한 사전 학습된 모델을 쉽게 사용할 수 있도록 지원합니다.\n","\n","# Hugging Face의 주요 특징 및 도구\n","# 1. Transformers 라이브러리\n","# Transformers 라이브러리는 Hugging Face에서 제공하는 가장 대표적인 오픈소스 라이브러리로, BERT, GPT-2, T5, RoBERTa 등과 같은 Transformer 기반의 사전 학습된 모델을 지원합니다. 이 라이브러리는 매우 다양한 언어 모델을 손쉽게 사용할 수 있게 하며, 텍스트 생성, 번역, 질문 답변, 텍스트 분류, 감정 분석 등 여러 NLP 작업을 수행할 수 있습니다.\n","\n","# 사전 학습된 모델: Hugging Face는 수천 개의 사전 학습된 모델을 제공하여 사용자가 자신만의 데이터를 사용해 쉽게 모델을 파인튜닝하거나 바로 사용할 수 있습니다.\n","# 지원되는 모델 종류: BERT, GPT, GPT-2, T5, RoBERTa, DistilBERT, MarianMT, BART 등.\n","# 다양한 작업: 텍스트 분류, 텍스트 생성, 번역, 질문 답변, 감정 분석 등.\n","# 2. Datasets 라이브러리\n","# Datasets 라이브러리는 Hugging Face에서 제공하는 또 다른 중요한 도구로, 다양한 공개 데이터셋에 대한 간편한 접근을 제공합니다. NLP 연구에서 자주 사용되는 대규모 데이터셋을 손쉽게 다운로드하고 사용할 수 있습니다.\n","\n","# 대규모 데이터셋 지원: Datasets 라이브러리를 통해 대규모 NLP 데이터셋을 쉽게 로드할 수 있습니다. 예를 들어, GLUE, SQuAD, COCO, CNN/DailyMail 등의 데이터셋이 지원됩니다.\n","# 빠르고 효율적: 대규모 데이터셋도 메모리 효율적으로 처리할 수 있으며, 다양한 포맷을 지원합니다.\n","# 3. Hugging Face Model Hub\n","# Hugging Face Model Hub는 다양한 사전 학습된 모델이 저장된 플랫폼으로, 수천 개의 프리트레인된 모델을 커뮤니티가 공유하고 사용할 수 있는 저장소입니다. 사용자는 여기서 텍스트 분류, 번역, 요약, 질문 답변 등의 작업에 적합한 모델을 검색하여 사용할 수 있습니다.\n","\n","# 모델 검색 및 다운로드: 특정 작업이나 언어에 적합한 사전 학습된 모델을 검색하고, 간단한 코드 한 줄로 불러올 수 있습니다.\n","# 모델 공유: 자신이 훈련한 모델을 커뮤니티와 공유할 수 있으며, 다른 사용자가 제공한 모델도 쉽게 사용할 수 있습니다.\n","# 4. Tokenizers 라이브러리\n","# Tokenizers는 고속으로 텍스트를 토큰화할 수 있도록 설계된 라이브러리로, Hugging Face의 모델을 사용할 때 필수적인 토큰화 과정을 매우 빠르고 효율적으로 수행합니다.\n","\n","# 다양한 토크나이저 지원: BERT, GPT-2, T5 등 각 모델에 최적화된 토크나이저를 제공합니다.\n","# 병렬 처리: 매우 빠른 속도로 대규모 텍스트 데이터를 병렬 처리할 수 있어 대규모 데이터셋을 다룰 때 유리합니다.\n","# 5. Gradio 및 Streamlit과의 통합\n","# Hugging Face는 Gradio와 Streamlit 같은 라이브러리와 통합되어, 머신러닝 모델을 쉽게 웹 인터페이스로 배포할 수 있습니다. 이를 통해 NLP 모델을 웹 애플리케이션으로 빠르게 배포하고, 실시간으로 결과를 확인할 수 있습니다.\n","\n","# 6. Hugging Face Spaces\n","# Hugging Face Spaces는 사용자가 쉽게 자신의 모델을 배포하고 공유할 수 있는 클라우드 플랫폼입니다. Streamlit이나 Gradio와 같은 인터페이스를 사용하여 웹 애플리케이션 형태로 모델을 배포할 수 있으며, 이를 통해 누구나 사용할 수 있도록 쉽게 공유할 수 있습니다.\n","\n","# 7. Community and Open Source\n","# Hugging Face는 오픈소스 커뮤니티에 큰 비중을 두고 있습니다. 많은 연구자, 개발자가 Hugging Face를 통해 자신들의 연구 결과나 툴을 공유하며, 그 결과 커뮤니티 주도로 모델과 데이터셋이 빠르게 발전하고 있습니다.\n","\n","# Hugging Face의 주요 응용 분야\n","# Hugging Face는 다양한 NLP 작업에 매우 유용합니다. 다음은 Hugging Face의 도구들이 사용되는 대표적인 분야입니다:\n","\n","# 텍스트 분류: 감정 분석, 주제 분류, 스팸 필터링 등.\n","# 기계 번역: 한 언어에서 다른 언어로 텍스트 번역.\n","# 텍스트 생성: 텍스트 완성, 이야기 생성, 챗봇 등.\n","# 질문 답변: 질문에 대한 자연스러운 답변 생성.\n","# 텍스트 요약: 긴 문서나 기사 등을 짧게 요약.\n","# Hugging Face의 장점\n","# 사용자 친화적: 코드 몇 줄만으로 강력한 NLP 모델을 불러와 사용할 수 있으며, 모델을 쉽게 파인튜닝할 수 있습니다.\n","# 풍부한 모델 및 데이터셋: 다양한 사전 학습된 모델과 데이터셋이 제공되어 연구 및 개발에 매우 유용합니다.\n","# 오픈소스: Hugging Face의 도구들은 오픈소스로 제공되어 누구나 무료로 사용할 수 있습니다.\n","# 빠른 배포: 모델을 학습하고 배포하는 과정이 매우 간단하며, Gradio, Streamlit 등을 통해 웹에서 모델을 실시간으로 사용할 수 있습니다."]},{"cell_type":"code","execution_count":null,"id":"75260d6a","metadata":{"id":"75260d6a"},"outputs":[],"source":["# *MarianTokenizer**가 SentencePiece 라이브러리를 필요\n","# SentencePiece는 Google에서 만든 텍스트 토크나이저이자 디토크나이저로, NLP 모델에서 자주 사용됩니다."]},{"cell_type":"code","execution_count":null,"id":"3c3e4918","metadata":{"id":"3c3e4918","outputId":"57caffeb-7171-424c-ba5e-db66d304f518"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n","Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n","   ---------------------------------------- 991.5/991.5 kB 5.8 MB/s eta 0:00:00\n","Installing collected packages: sentencepiece\n","Successfully installed sentencepiece-0.2.0\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -illow (c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n","WARNING: Error parsing dependencies of ipykernel: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n","    matplotlib-inline (<0.2.0appnope,>=0.1.0) ; platform_system == \"Darwin\"\n","                      ~~~~~~~~^\n","WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -illow (c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n","WARNING: Ignoring invalid distribution -illow (c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"]}],"source":["pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"id":"2f80c51d","metadata":{"id":"2f80c51d","outputId":"ab01b7fe-53ca-4f44-9992-f5512da70d0c"},"outputs":[{"ename":"OSError","evalue":"Helsinki-NLP/opus-mt-en-ko is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 953\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    954\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/Helsinki-NLP/opus-mt-en-ko/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\utils\\hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[1;31m# Load from URL or cache if already cached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[0;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[0;32m    863\u001b[0m             \u001b[1;31m# Destination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    968\u001b[0m         \u001b[1;31m# Otherwise, raise appropriate error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 969\u001b[1;33m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[1;31m# Repo not found or gated => let's raise the actual error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[0;32m   1377\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[1;31m# Retrieve metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m     r = _request_wrapper(\n\u001b[0m\u001b[0;32m   1297\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"HEAD\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         response = _request_wrapper(\n\u001b[0m\u001b[0;32m    278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    453\u001b[0m             )\n\u001b[1;32m--> 454\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-6719e125-2478cb0e183fc7f028349265;e252119f-a308-4efb-9022-86bb5fb8ae14)\n\nRepository Not Found for url: https://huggingface.co/Helsinki-NLP/opus-mt-en-ko/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4864/279571245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 사전 학습된 영어 -> 한국어 번역 모델 로드\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Helsinki-NLP/opus-mt-en-ko'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMarianTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMarianMTModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2125\u001b[0m                     \u001b[1;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m                     \u001b[0mfast_tokenizer_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2127\u001b[1;33m                     resolved_config_file = cached_file(\n\u001b[0m\u001b[0;32m   2128\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m                         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\utils\\hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m         ) from e\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         raise EnvironmentError(\n\u001b[0m\u001b[0;32m    427\u001b[0m             \u001b[1;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[1;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mOSError\u001b[0m: Helsinki-NLP/opus-mt-en-ko is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"]}],"source":["from transformers import MarianMTModel, MarianTokenizer\n","\n","# 사전 학습된 영어 -> 한국어 번역 모델 로드\n","model_name = 'Helsinki-NLP/opus-mt-en-ko'\n","tokenizer = MarianTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name)\n","\n","# 번역할 문장\n","english_text = \"I am a student.\"\n","\n","# 입력 문장을 토큰화\n","inputs = tokenizer(english_text, return_tensors=\"pt\", padding=True)\n","\n","# 모델을 사용해 번역\n","translated = model.generate(**inputs)\n","\n","# 번역된 텍스트 디코딩\n","korean_translation = tokenizer.decode(translated[0], skip_special_tokens=True)\n","\n","# 결과 출력\n","print(\"Original English Text:\", english_text)\n","print(\"Translated Korean Text:\", korean_translation)\n"]},{"cell_type":"code","execution_count":null,"id":"d0cda8c6","metadata":{"id":"d0cda8c6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"feab864c","metadata":{"id":"feab864c","outputId":"2e6b8dfb-3652-4199-e9af-986abac12e24"},"outputs":[{"ename":"RuntimeError","evalue":"module compiled against API version 0x10 but this version of numpy is 0xe","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xe"]},{"ename":"SystemError","evalue":"initialization of _pywrap_checkpoint_reader raised unreported exception","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2256/514945594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 단순한 임베딩 레이어 및 포지셔널 인코딩을 포함한 Transformer 모델\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[1;31m# line: 456\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[1;31m# line: 365\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[1;31m# line: 418\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_all_reduce_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_server_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcross_device_ops_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvalue_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\values.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstruct_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpacked_distributed_variable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpacked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreduce_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mag_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_autograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdebug_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnested_structure_coder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_checkpoint_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mSystemError\u001b[0m: initialization of _pywrap_checkpoint_reader raised unreported exception"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Embedding, LayerNormalization, Dropout\n","import numpy as np\n","\n","# 단순한 임베딩 레이어 및 포지셔널 인코딩을 포함한 Transformer 모델\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, max_pos_encoding, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.tokenizer = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = self.positional_encoding(max_pos_encoding, d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],\n","                                     np.arange(d_model)[np.newaxis, :],\n","                                     d_model)\n","        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # 짝수 인덱스: 사인 적용\n","        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # 홀수 인덱스: 코사인 적용\n","        pos_encoding = angle_rads[np.newaxis, ...]\n","        return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","    def get_angles(self, pos, i, d_model):\n","        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","        return pos * angle_rates\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","        x = self.tokenizer(x)  # 임베딩 레이어 적용\n","        x += self.pos_encoding[:, :seq_len, :]\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(len(self.enc_layers)):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x\n","\n","# 기본적인 Encoder 레이어 구조\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output = self.mha(x, x, x, mask)  # Self-attention\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)  # Residual 연결 + Layernorm\n","\n","        ffn_output = self.ffn(out1)  # Feed-forward network\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)  # Residual 연결 + Layernorm\n","\n","        return out2\n","\n","# 멀티헤드 어텐션 레이어\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        scaled_attention, _ = scaled_dot_product_attention(q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        return output\n","\n","# Scaled dot-product attention\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)  # 마스킹된 부분은 매우 작은 값으로 설정\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (batch_size, num_heads, seq_len_q, seq_len_k)\n","    output = tf.matmul(attention_weights, v)  # (batch_size, num_heads, seq_len_q, depth_v)\n","\n","    return output, attention_weights\n","\n","# 포인트-와이즈 피드포워드 네트워크\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","        Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])\n","\n","# \"I am a student\"에 대한 임의 입력 데이터\n","tokenized_sentence = [1, 4, 3, 5]  # \"I am a student\"라는 문장의 단순화된 토큰화 (단어에 대한 임의 번호)\n","tokenized_sentence = tf.convert_to_tensor([tokenized_sentence])\n","\n","# Transformer 모델 생성\n","transformer = Transformer(num_layers=2, d_model=512, num_heads=8, dff=2048, input_vocab_size=10000, target_vocab_size=10000, max_pos_encoding=5000)\n","\n","# 모델 출력\n","output = transformer(tokenized_sentence, training=False, mask=None)\n","print(output.shape)  # (batch_size, input_seq_len, d_model)\n"]},{"cell_type":"code","execution_count":null,"id":"c2cd1e99","metadata":{"id":"c2cd1e99"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d047d5ca","metadata":{"id":"d047d5ca"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9ea64daa","metadata":{"id":"9ea64daa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"47c99767","metadata":{"id":"47c99767","outputId":"a8ea96b2-006c-454f-f001-e89d01ee0902"},"outputs":[{"ename":"RuntimeError","evalue":"module compiled against API version 0x10 but this version of numpy is 0xe","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xe"]},{"ename":"SystemError","evalue":"initialization of _pywrap_checkpoint_reader raised unreported exception","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2256/2318421850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 하이퍼파라미터 설정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0md_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m512\u001b[0m  \u001b[1;31m# 임베딩 벡터의 차원\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[1;31m# line: 456\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[1;31m# line: 365\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[1;31m# line: 418\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_all_reduce_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_server_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcross_device_ops_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvalue_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\values.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstruct_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpacked_distributed_variable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpacked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreduce_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mag_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_autograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdebug_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnested_structure_coder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections_abc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_checkpoint_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mSystemError\u001b[0m: initialization of _pywrap_checkpoint_reader raised unreported exception"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","# 하이퍼파라미터 설정\n","d_model = 512  # 임베딩 벡터의 차원\n","num_heads = 8  # Multi-Head Attention에서의 헤드 수\n","num_layers = 6  # 인코더와 디코더 층의 개수\n","dff = 2048  # 피드포워드 네트워크의 차원\n","input_vocab_size = 8500  # 입력 어휘 크기\n","target_vocab_size = 8000  # 출력 어휘 크기\n","max_seq_len = 100  # 최대 시퀀스 길이\n","dropout_rate = 0.1  # 드롭아웃 비율\n","\n","# 포지셔널 인코딩(Positional Encoding) 구현\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","\n","    # 짝수 인덱스는 sin, 홀수 인덱스는 cos 적용\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])  # 짝수 인덱스\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])  # 홀수 인덱스\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","# 멀티헤드 어텐션(Multi-Head Attention) 구현\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model)\n","        self.wk = tf.keras.layers.Dense(d_model)\n","        self.wv = tf.keras.layers.Dense(d_model)\n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        \"\"\"입력을 (batch_size, num_heads, seq_len, depth)로 분리\"\"\"\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)  # (batch_size, seq_len, d_model)\n","        k = self.wk(k)  # (batch_size, seq_len, d_model)\n","        v = self.wv(v)  # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n","\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","\n","        return output, attention_weights\n","\n","# Scaled Dot-Product Attention 구현\n","def scaled_dot_product_attention(q, k, v, mask):\n","    \"\"\"어텐션 가중치를 계산\"\"\"\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","\n","    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","    return output, attention_weights\n","\n","# 포지션별 피드포워드 네트워크\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","    ])\n","\n","# 인코더 블록 구현\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n","\n","# 인코더 구현\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","\n","        # 임베딩 및 포지셔널 인코딩 추가\n","        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x  # (batch_size, input_seq_len, d_model)\n","\n","# Transformer 모델 구현 (인코더 중심)\n","class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n","\n","    def call(self, inp, training, enc_padding_mask):\n","        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","        return enc_output\n"]},{"cell_type":"code","execution_count":null,"id":"57d238f1","metadata":{"id":"57d238f1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e24b2f54","metadata":{"id":"e24b2f54"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"4cd8cfb4","metadata":{"id":"4cd8cfb4"},"source":["# 준비"]},{"cell_type":"markdown","id":"1420c6c7","metadata":{"id":"1420c6c7"},"source":["## 라이브러리"]},{"cell_type":"code","execution_count":null,"id":"2d05ba97","metadata":{"id":"2d05ba97"},"outputs":[],"source":["# TensorFlow와 Keras를 사용하여 Transformer의 핵심 요소인 Multi-Head Attention과 Encoder-Decoder 구조를 구현하는 방식입니다."]},{"cell_type":"code","execution_count":null,"id":"42c5180a","metadata":{"id":"42c5180a"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LayerNormalization, Dropout\n","from tensorflow.keras.models import Model"]},{"cell_type":"markdown","id":"a040a585","metadata":{"id":"a040a585"},"source":["## Multi-Head Attention Layer 정의"]},{"cell_type":"code","execution_count":null,"id":"cb0a43a5","metadata":{"id":"cb0a43a5"},"outputs":[],"source":["# MultiHeadAttention 클래스는 논문에서 설명된 다중 어텐션 메커니즘을 구현합니다.\n","\n","# split_heads 함수는 입력 벡터를 여러 헤드로 나누고, 각 헤드마다 다른 Self-Attention을 적용한 후 다시 결합합니다.\n","# scaled_dot_product_attention는 어텐션 메커니즘의 핵심인 어텐션 점수를 계산하여, 각 값에 가중합을 적용합니다."]},{"cell_type":"code","execution_count":null,"id":"698be498","metadata":{"id":"698be498"},"outputs":[],"source":["# Multi-Head Attention Layer 정의\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","        output = self.dense(concat_attention)\n","        return output, attention_weights\n"]},{"cell_type":"markdown","id":"50a9420b","metadata":{"id":"50a9420b"},"source":["## Scaled Dot-Product Attention 정의"]},{"cell_type":"code","execution_count":null,"id":"51f2bac0","metadata":{"id":"51f2bac0"},"outputs":[],"source":["# Scaled Dot-Product Attention 정의\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n"]},{"cell_type":"markdown","id":"b7104cf7","metadata":{"id":"b7104cf7"},"source":["## Transformer Encoder Layer 정의"]},{"cell_type":"code","execution_count":null,"id":"4229b6aa","metadata":{"id":"4229b6aa"},"outputs":[],"source":["\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n","\n","# Feed Forward Network 정의\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),\n","        Dense(d_model)\n","    ])\n"]},{"cell_type":"markdown","id":"57ac76fe","metadata":{"id":"57ac76fe"},"source":["## Feed Forward Network 정의"]},{"cell_type":"code","execution_count":null,"id":"6d3fd71f","metadata":{"id":"6d3fd71f"},"outputs":[],"source":["\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),\n","        Dense(d_model)\n","    ])"]},{"cell_type":"markdown","id":"3c7bd1c9","metadata":{"id":"3c7bd1c9"},"source":["## Positional Encoding"]},{"cell_type":"code","execution_count":null,"id":"790d28e9","metadata":{"id":"790d28e9"},"outputs":[],"source":["# Transformer 모델은 RNN과 달리 순차 데이터에 대한 순서 정보를 자연스럽게 처리할 수 없기 때문에, Positional Encoding을 추가하여 입력 순서 정보를 반영합니다.\n","# positional_encoding 함수는 입력 시퀀스의 각 위치에 대해 사인과 코사인 함수를 적용하여, 모델이 위치 정보를 학습할 수 있도록 합니다."]},{"cell_type":"code","execution_count":null,"id":"938462bc","metadata":{"id":"938462bc"},"outputs":[],"source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","\n","    sines = np.sin(angle_rads[:, 0::2])\n","    cosines = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n"]},{"cell_type":"markdown","id":"197e4d5a","metadata":{"id":"197e4d5a"},"source":["## Transformer Encoder 정의"]},{"cell_type":"code","execution_count":null,"id":"f278919e","metadata":{"id":"f278919e"},"outputs":[],"source":["# Encoder Layer:\n","\n","# EncoderLayer는 하나의 인코더 층을 정의합니다. 각 층은 Multi-Head Attention과 **Feed Forward Network(FFN)**으로 구성됩니다.\n","# Residual 연결 및 Layer Normalization을 통해 학습을 안정적으로 수행할 수 있습니다.\n","\n","# Encoder:\n","\n","# Encoder 클래스는 여러 개의 EncoderLayer를 쌓아 전체 인코더 블록을 구현합니다.\n","# 입력 시퀀스는 임베딩된 후, 위치 정보를 반영하여 각 인코더 층을 거쳐 처리됩니다."]},{"cell_type":"code","execution_count":null,"id":"eab1daef","metadata":{"id":"eab1daef","outputId":"caaaa5ef-a0f5-4018-d114-115ec85a3c3d"},"outputs":[{"ename":"ValueError","evalue":"Exception encountered when calling Encoder.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Encoder.call():\n  • x=tf.Tensor(shape=(64, 62), dtype=float32)\n  • training=False\n  • mask=None","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16352/2037898466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0msample_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_vocab_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximum_position_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mtemp_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m62\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0msample_transformer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_transformer_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16352/2037898466.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, training, mask)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Encoder.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: False (of type <class 'bool'>)\u001b[0m\n\nArguments received by Encoder.call():\n  • x=tf.Tensor(shape=(64, 62), dtype=float32)\n  • training=False\n  • mask=None"]}],"source":["# Transformer Encoder 정의\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x\n","\n","    # 샘플 모델 학습\n","sample_transformer = Encoder(num_layers=2, d_model=512, num_heads=8, dff=2048, input_vocab_size=8500, maximum_position_encoding=10000)\n","temp_input = tf.random.uniform((64, 62))\n","sample_transformer_output = sample_transformer(temp_input, training=False, mask=None)\n","print(sample_transformer_output.shape)"]},{"cell_type":"code","execution_count":null,"id":"11bc61c3","metadata":{"id":"11bc61c3"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"5ab447eb","metadata":{"id":"5ab447eb"},"source":["# 종합"]},{"cell_type":"code","execution_count":null,"id":"af9fc1b1","metadata":{"id":"af9fc1b1"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LayerNormalization, Dropout\n","from tensorflow.keras.models import Model\n","\n","# Multi-Head Attention Layer 정의\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","        output = self.dense(concat_attention)\n","        return output, attention_weights\n","\n","# Scaled Dot-Product Attention 정의\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n","\n","# Transformer Encoder Layer 정의\n","class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output)\n","\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)\n","\n","        return out2\n","\n","# Feed Forward Network 정의\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),\n","        Dense(d_model)\n","    ])\n","\n","# Positional Encoding 정의\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","\n","    sines = np.sin(angle_rads[:, 0::2])\n","    cosines = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","# Transformer Encoder 정의\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def call(self, x, training, mask):\n","        seq_len = tf.shape(x)[1]\n","\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","\n","        return x\n","\n","# 샘플 모델 학습\n","sample_transformer = Encoder(num_layers=2, d_model=512, num_heads=8, dff=2048, input_vocab_size=8500, maximum_position_encoding=10000)\n","temp_input = tf.random.uniform((64, 62))\n","sample_transformer_output = sample_transformer(temp_input, training=False, mask=None)\n","print(sample_transformer_output.shape)\n"]},{"cell_type":"markdown","id":"a7c1f9fe","metadata":{"id":"a7c1f9fe"},"source":["# Decoder"]},{"cell_type":"code","execution_count":null,"id":"6b7aec15","metadata":{"id":"6b7aec15"},"outputs":[],"source":["# Decoder: 인코더와 유사한 구조로, 입력 시퀀스를 받아 최종 출력을 생성하는 과정이 필요합니다. 디코더는 인코더-디코더 어텐션을 통해 인코더에서 생성된 정보와 상호작용합니다.\n","# Loss function & Optimizer: 손실 함수는 Sparse Categorical Crossentropy와 같은 분류용 손실 함수를 사용하고, 최적화는 Adam을 사용합니다."]},{"cell_type":"code","execution_count":null,"id":"7d0e0e68","metadata":{"id":"7d0e0e68"},"outputs":[],"source":["#  Transformer 모델의 디코더(Decoder) 부분을 구현한 코드입니다.\n","#     디코더는 **인코더-디코더 어텐션(Encoder-Decoder Attention)**과 Masked Multi-Head Attention을 포함하며, 이를 통해 입력 시퀀스를 받아 최종 출력을 생성하는 역할을 합니다."]},{"cell_type":"code","execution_count":null,"id":"f1450a79","metadata":{"id":"f1450a79"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LayerNormalization, Dropout\n"]},{"cell_type":"code","execution_count":null,"id":"8cf14b23","metadata":{"id":"8cf14b23"},"outputs":[],"source":["# Masked Multi-Head Attention:\n","# 디코더에서 첫 번째 Multi-Head Attention은 Masked Self-Attention입니다.\n","# 이는 디코더의 출력이 순차적으로 생성되기 때문에, 현재 토큰 이후의 정보는 마스킹하여 미래 정보를 참조하지 않도록 합니다.\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3b4e0f0a","metadata":{"id":"3b4e0f0a"},"outputs":[],"source":["\n","# Scaled Dot-Product Attention 정의 (위 코드와 동일)\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n"]},{"cell_type":"code","execution_count":null,"id":"89a4f79f","metadata":{"id":"89a4f79f"},"outputs":[],"source":["\n","# Encoder-Decoder Attention:\n","# 디코더에서 두 번째 Multi-Head Attention은 인코더 출력을 입력으로 받아, 인코더에서 처리된 정보를 디코더가 참조할 수 있게 합니다.\n","# 이를 통해 인코더-디코더 간 상호작용이 이루어집니다.\n"]},{"cell_type":"code","execution_count":null,"id":"f5e82940","metadata":{"id":"f5e82940"},"outputs":[],"source":["# Multi-Head Attention Layer 정의 (위 코드와 동일)\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","        output = self.dense(concat_attention)\n","        return output, attention_weights\n"]},{"cell_type":"code","execution_count":null,"id":"dad3eb80","metadata":{"id":"dad3eb80"},"outputs":[],"source":["# Feed Forward Network:\n","\n","# FFN(Point-Wise Feed Forward Network)는 인코더와 마찬가지로 각 디코더 층에서 사용됩니다.\n","# 이는 각 층의 출력을 비선형적으로 변환하는 역할을 합니다.\n"]},{"cell_type":"code","execution_count":null,"id":"9d4d9572","metadata":{"id":"9d4d9572"},"outputs":[],"source":["# Feed Forward Network 정의 (위 코드와 동일)\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),\n","        Dense(d_model)\n","    ])"]},{"cell_type":"code","execution_count":null,"id":"669cd8ee","metadata":{"id":"669cd8ee"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8c66d829","metadata":{"id":"8c66d829"},"outputs":[],"source":["# Transformer Decoder Layer 정의\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.dropout3 = Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        # 첫 번째 Multi-Head Attention (Masked Multi-Head Attention)\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        # 두 번째 Multi-Head Attention (Encoder-Decoder Attention)\n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","\n","        # Feed Forward Network\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","\n","        return out3, attn_weights_block1, attn_weights_block2\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8632c51e","metadata":{"id":"8632c51e"},"outputs":[],"source":["\n","# Decoder Class:\n","# 디코더는 여러 개의 DecoderLayer를 쌓아서 구성되며,\n","# 각 층에서는 Masked Multi-Head Attention, Encoder-Decoder Attention, FFN을 통해 데이터를 처리합니다."]},{"cell_type":"code","execution_count":null,"id":"ea44f1cb","metadata":{"id":"ea44f1cb"},"outputs":[],"source":["# Transformer Decoder 정의\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n","            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n","            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n","\n","        return x, attention_weights\n","\n"]},{"cell_type":"code","execution_count":null,"id":"b54df7fb","metadata":{"id":"b54df7fb"},"outputs":[],"source":["# Positional Encoding:\n","# 인코더와 마찬가지로 디코더에서도 Positional Encoding을 사용하여 입력 시퀀스의 위치 정보를 모델이 학습할 수 있도록 합니다.\n"]},{"cell_type":"code","execution_count":null,"id":"e6419790","metadata":{"id":"e6419790"},"outputs":[],"source":["# Positional Encoding 정의 (위 코드에서 이미 사용된 함수)\n","import numpy as np\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","\n","    sines = np.sin(angle_rads[:, 0::2])\n","    cosines = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","# 샘플 디코더 테스트\n","sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, dff=2048, target_vocab_size=8000, maximum_position_encoding=5000)\n","temp_input = tf.random.uniform((64, 26))\n","sample_decoder_output, attn_weights = sample_decoder(temp_input, enc_output=sample_transformer_output, training=False, look_ahead_mask=None, padding_mask=None)\n","\n","print(sample_decoder_output.shape)"]},{"cell_type":"code","execution_count":null,"id":"92c1e3b5","metadata":{"id":"92c1e3b5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"54c5e390","metadata":{"id":"54c5e390"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ca7bfab0","metadata":{"id":"ca7bfab0"},"outputs":[],"source":["# 종합"]},{"cell_type":"code","execution_count":null,"id":"0004ef35","metadata":{"id":"0004ef35"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LayerNormalization, Dropout\n","\n","# Scaled Dot-Product Attention 정의 (위 코드와 동일)\n","def scaled_dot_product_attention(q, k, v, mask):\n","    matmul_qk = tf.matmul(q, k, transpose_b=True)\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)\n","\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n","    output = tf.matmul(attention_weights, v)\n","    return output, attention_weights\n","\n","# Multi-Head Attention Layer 정의 (위 코드와 동일)\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = Dense(d_model)\n","        self.wk = Dense(d_model)\n","        self.wv = Dense(d_model)\n","\n","        self.dense = Dense(d_model)\n","\n","    def split_heads(self, x, batch_size):\n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","\n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q)\n","        k = self.wk(k)\n","        v = self.wv(v)\n","\n","        q = self.split_heads(q, batch_size)\n","        k = self.split_heads(k, batch_size)\n","        v = self.split_heads(v, batch_size)\n","\n","        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","        output = self.dense(concat_attention)\n","        return output, attention_weights\n","\n","# Feed Forward Network 정의 (위 코드와 동일)\n","def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        Dense(dff, activation='relu'),\n","        Dense(d_model)\n","    ])\n","\n","# Transformer Decoder Layer 정의\n","class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = Dropout(rate)\n","        self.dropout2 = Dropout(rate)\n","        self.dropout3 = Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        # 첫 번째 Multi-Head Attention (Masked Multi-Head Attention)\n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        # 두 번째 Multi-Head Attention (Encoder-Decoder Attention)\n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)\n","\n","        # Feed Forward Network\n","        ffn_output = self.ffn(out2)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)\n","\n","        return out3, attn_weights_block1, attn_weights_block2\n","\n","# Transformer Decoder 정의\n","class Decoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n","        super(Decoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = Dropout(rate)\n","\n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        seq_len = tf.shape(x)[1]\n","        attention_weights = {}\n","\n","        x = self.embedding(x)\n","        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        x += self.pos_encoding[:, :seq_len, :]\n","\n","        x = self.dropout(x, training=training)\n","\n","        for i in range(self.num_layers):\n","            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n","            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n","            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n","\n","        return x, attention_weights\n","\n","# Positional Encoding 정의 (위 코드에서 이미 사용된 함수)\n","import numpy as np\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n","\n","    sines = np.sin(angle_rads[:, 0::2])\n","    cosines = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = np.concatenate([sines, cosines], axis=-1)\n","    pos_encoding = pos_encoding[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","# 샘플 디코더 테스트\n","sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, dff=2048, target_vocab_size=8000, maximum_position_encoding=5000)\n","temp_input = tf.random.uniform((64, 26))\n","sample_decoder_output, attn_weights = sample_decoder(temp_input, enc_output=sample_transformer_output, training=False, look_ahead_mask=None, padding_mask=None)\n","\n","print(sample_decoder_output.shape)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.11"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":5}