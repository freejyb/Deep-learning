{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647e2dc9",
   "metadata": {},
   "source": [
    "# 합성곱 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50f178",
   "metadata": {},
   "source": [
    "## 합성곱 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 연산은 필터(커널)를 이미지에 적용해 특정한 특징을 추출하는 작업입니다. \n",
    "#이 작업은 이미지의 작은 영역에 필터를 움직여가며 합성곱을 수행하는 것으로 이루어집니다. \n",
    "# 이를 수학적으로 표현하면, 필터와 이미지의 각 영역의 요소를 곱한 후 더한 값을 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 수학적 설명:\n",
    "# 주어진 필터(커널)와 이미지에 대해, 필터가 이미지의 작은 부분을 순서대로 이동하면서 각 필터 요소와 해당 이미지 영역의 요소를 곱한 후 그 합을 구합니다.\n",
    "# 예를 들어,  3 × 3크기의 필터를  5 × 5 이미지에 적용한다고 가정하면, 다음과 같은 방식으로 연산이 이루어집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d8510",
   "metadata": {},
   "source": [
    "## 코드 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1228d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 설명:\n",
    "# 이미지와 필터(커널)를 각각 5x5, 3x3 크기의 행렬로 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f028663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image: 합성곱 연산을 수행할 입력 이미지입니다.\n",
    "# kernel: 3x3 크기의 필터로, 특징을 추출하기 위해 사용됩니다.\n",
    "# 출력 크기는 필터가 이동할 수 있는 범위에 따라 결정됩니다. 입력 이미지의 크기에서 필터 크기를 뺀 값에 1을 더한 크기로 결정됩니다.\n",
    "\n",
    "# 합성곱 연산은 이미지의 각 위치에서 필터를 적용하여 이루어집니다.\n",
    "\n",
    "# region = image[i:i + kernel.shape[0], j:j + kernel.shape[1]]: 필터 크기만큼 이미지의 영역을 선택합니다.\n",
    "# np.sum(region * kernel): 선택된 이미지 영역과 필터 요소별로 곱하고 그 합을 구하여 출력 배열에 저장합니다.\n",
    "\n",
    "# 최종적으로 합성곱 결과를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89863b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 이미지:\n",
      " [[1 2 0 1 2]\n",
      " [0 1 2 0 1]\n",
      " [2 1 0 1 2]\n",
      " [1 0 1 2 0]\n",
      " [0 2 1 0 1]]\n",
      "필터(커널):\n",
      " [[ 1  0 -1]\n",
      " [ 1  0 -1]\n",
      " [ 1  0 -1]]\n",
      "합성곱 결과:\n",
      " [[ 1.  2. -3.]\n",
      " [ 0. -1.  0.]\n",
      " [ 1.  0. -1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 이미지 (5x5 행렬로 표현)\n",
    "image = np.array([[1, 2, 0, 1, 2],\n",
    "                  [0, 1, 2, 0, 1],\n",
    "                  [2, 1, 0, 1, 2],\n",
    "                  [1, 0, 1, 2, 0],\n",
    "                  [0, 2, 1, 0, 1]])\n",
    "\n",
    "# 필터(커널) (3x3 행렬로 표현)\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "# 출력 크기 계산 (Stride=1, Padding=0)\n",
    "output_height = image.shape[0] - kernel.shape[0] + 1\n",
    "output_width = image.shape[1] - kernel.shape[1] + 1\n",
    "\n",
    "# 출력 행렬 초기화\n",
    "output = np.zeros((output_height, output_width))\n",
    "\n",
    "# 합성곱 연산 수행\n",
    "for i in range(output_height):\n",
    "    for j in range(output_width):\n",
    "        # 이미지의 현재 위치에서 커널과 곱한 후 더한 값을 저장\n",
    "        region = image[i:i + kernel.shape[0], j:j + kernel.shape[1]]\n",
    "        output[i, j] = np.sum(region * kernel)\n",
    "\n",
    "print(\"입력 이미지:\\n\", image)\n",
    "print(\"필터(커널):\\n\", kernel)\n",
    "print(\"합성곱 결과:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ef619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명:\n",
    "# 필터가 이미지에서 한 칸씩 움직이며 합성곱 연산을 수행합니다.\n",
    "# 필터는 주로 가중치 역할을 하여 이미지의 특정 특징(예: 가장자리, 패턴 등)을 추출하는 데 사용됩니다.\n",
    "# 출력된 결과는 입력 이미지에서 필터로 추출된 특징이 반영된 새로운 특성 맵입니다.\n",
    "# 이 코드 예시는 CNN에서 중요한 합성곱 연산이 어떻게 수행되는지를 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947dd89e",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe984f6",
   "metadata": {},
   "source": [
    "## 패딩 없이 합성곱 (valid padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 없이 합성곱 (Valid Padding):\n",
    "\n",
    "# 입력 데이터와 필터를 사용하여 패딩 없이 합성곱 연산을 수행합니다.\n",
    "# 출력 크기는 필터 크기만큼 줄어들며, 입력 크기보다 작아집니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb969aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Padding (No Padding) 결과:\n",
      "[[-6.  1.  4.]\n",
      " [-2. -2. -1.]\n",
      " [-1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def conv2d(input_data, kernel, stride=1, padding=0):\n",
    "    # 입력 크기\n",
    "    input_height, input_width = input_data.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # 출력 크기 계산 (Valid Padding)\n",
    "    output_height = (input_height - kernel_height + 2 * padding) // stride + 1\n",
    "    output_width = (input_width - kernel_width + 2 * padding) // stride + 1\n",
    "    \n",
    "    # 출력 초기화\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    # 패딩이 없는 경우\n",
    "    padded_input = input_data\n",
    "\n",
    "    # 합성곱 연산\n",
    "    for i in range(0, output_height):\n",
    "        for j in range(0, output_width):\n",
    "            output[i, j] = np.sum(padded_input[i:i + kernel_height, j:j + kernel_width] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 입력 데이터 (5x5)\n",
    "input_data = np.array([[1, 2, 3, 0, 1],\n",
    "                       [0, 1, 2, 3, 1],\n",
    "                       [1, 2, 3, 1, 2],\n",
    "                       [2, 1, 0, 2, 3],\n",
    "                       [1, 1, 2, 1, 0]])\n",
    "\n",
    "# 필터(커널) (3x3)\n",
    "kernel = np.array([[1, 0, -1],\n",
    "                   [1, 0, -1],\n",
    "                   [1, 0, -1]])\n",
    "\n",
    "# 패딩 없이 합성곱 수행\n",
    "output_valid = conv2d(input_data, kernel, stride=1, padding=0)\n",
    "print(\"Valid Padding (No Padding) 결과:\")\n",
    "print(output_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee02872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론:\n",
    "# Valid Padding: 패딩 없이 합성곱을 수행한 경우, 입력 크기가 줄어듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a655e",
   "metadata": {},
   "source": [
    "## 패딩을 적용한 합성곱 (same padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc963d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패딩 적용한 합성곱 (Same Padding):\n",
    "\n",
    "# 입력 데이터에 패딩을 추가하여 합성곱 연산을 수행합니다. 패딩 크기 \n",
    "# 𝑃=1을 적용하여 입력 이미지가 0으로 채워집니다.\n",
    "# 출력 크기는 입력 크기와 동일하게 유지됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97dac45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Same Padding (Padding = 1) 결과:\n",
      "[[-3. -4.  0.  3.  3.]\n",
      " [-5. -6.  1.  4.  4.]\n",
      " [-4. -2. -2. -1.  6.]\n",
      " [-4. -1.  0.  0.  4.]\n",
      " [-2.  1. -1. -1.  3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv2d_with_padding(input_data, kernel, stride=1, padding=1):\n",
    "    # 입력 크기\n",
    "    input_height, input_width = input_data.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    # 출력 크기 계산 (Same Padding)\n",
    "    output_height = (input_height - kernel_height + 2 * padding) // stride + 1\n",
    "    output_width = (input_width - kernel_width + 2 * padding) // stride + 1\n",
    "    \n",
    "    # 입력에 패딩 추가 (가장자리 0으로 채우기)\n",
    "    padded_input = np.pad(input_data, ((padding, padding), (padding, padding)), mode='constant')\n",
    "\n",
    "    # 출력 초기화\n",
    "    output = np.zeros((output_height, output_width))\n",
    "\n",
    "    # 합성곱 연산\n",
    "    for i in range(0, output_height):\n",
    "        for j in range(0, output_width):\n",
    "            output[i, j] = np.sum(padded_input[i:i + kernel_height, j:j + kernel_width] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 패딩 적용한 합성곱 수행\n",
    "output_same = conv2d_with_padding(input_data, kernel, stride=1, padding=1)\n",
    "print(\"\\nSame Padding (Padding = 1) 결과:\")\n",
    "print(output_same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same Padding: 입력 이미지에 패딩을 추가하여 출력 크기를 입력 크기와 동일하게 유지합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1bd124",
   "metadata": {},
   "source": [
    "# Pooling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling은 CNN(Convolutional Neural Network) 모델에서 차원을 축소하고, \n",
    "# 연산량을 줄이며, 중요한 특징을 유지하면서 모델의 과적합을 방지하기 위해 사용되는 중요한 연산입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa165752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 많이 사용되는 풀링 방식에는 **최대 풀링(Max Pooling)**과 **평균 풀링(Average Pooling)**이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16ff2d",
   "metadata": {},
   "source": [
    "## Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f6128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling(최대 풀링): 영역 내에서 가장 큰 값을 선택하여 그 영역을 대표합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48e4e4",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab74ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋을 CNN에 적합한 형태로 변환하고 정규화하는 작업을 수행합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f173f7",
   "metadata": {},
   "source": [
    "1. 데이터 준비 (MNIST 데이터셋 로드)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4705cbde",
   "metadata": {},
   "source": [
    "## 라이브러리,데이터 준비, 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110558f9",
   "metadata": {},
   "source": [
    "2. 데이터 전처리 (reshape 및 정규화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0216c",
   "metadata": {},
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be2f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적: CNN 모델에 입력할 수 있도록 이미지의 형태를 변환합니다.\n",
    "# reshape() 함수는 입력 데이터의 차원을 변경합니다.\n",
    "# 입력 데이터: x_train은 MNIST 데이터셋의 이미지 데이터로, 크기가 (60000, 28, 28)입니다. \n",
    "#이는 60,000개의 28x28 크기의 이미지들이 포함된 3D 배열입니다.\n",
    "\n",
    "# -1: -1은 남은 차원을 자동으로 계산하라는 의미입니다. 60,000개의 샘플이 있으므로, reshape 후 첫 번째 차원은 60,000으로 자동 계산됩니다.\n",
    "# 28, 28: 각 샘플 이미지는 28x28 크기의 2D 배열입니다.\n",
    "# 1: 마지막 차원인 1은 채널을 의미합니다. MNIST 데이터셋은 흑백 이미지로, 채널 수가 1입니다. 만약 컬러 이미지였다면 채널 수가 3(RGB)을 가질 것입니다.\n",
    "\n",
    "# x_train.reshape(-1, 28, 28, 1) : 60,000개의 28x28 크기의 흑백 이미지를 CNN에서 처리할 수 있도록 4D 텐서로 변환하는 작업입니다. \n",
    "# CNN의 합성곱 계층은 4차원 텐서를 입력으로 받습니다. (배치 크기, 높이, 너비, 채널)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13827445",
   "metadata": {},
   "source": [
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37136b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적: 테스트 데이터셋(x_test)도 CNN에 입력할 수 있도록 동일한 방식으로 차원을 변환합니다.\n",
    "# 입력 데이터: x_test는 10,000개의 28x28 크기 이미지들로 구성되어 있으며, 이를 (10000, 28, 28, 1) 크기로 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83a05e",
   "metadata": {},
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd47fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적: 이미지 데이터를 정규화하여 학습이 더 효율적으로 이루어지도록 만듭니다.\n",
    "# MNIST 데이터셋의 각 픽셀 값은 0부터 255까지의 값을 가집니다. 픽셀 값이 0이면 검정색, 255면 흰색을 의미합니다.\n",
    "# 정규화 과정:\n",
    "# x_train / 255.0: 픽셀 값을 0~255 범위에서 0~1 범위로 변환하는 작업입니다. \n",
    "# CNN 모델은 입력 값이 0~1 범위에 있을 때 더 빠르고 안정적으로 학습할 수 있기 때문에, 이 작업을 통해 데이터를 정규화합니다.\n",
    "# x_test / 255.0: 테스트 데이터셋도 동일한 방식으로 정규화됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82e8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 1. 데이터 준비 (MNIST 데이터셋 로드)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 2. 데이터 전처리 (reshape 및 정규화)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # (60000, 28, 28, 1)로 변환\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)    # (10000, 28, 28, 1)로 변환\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # 0~1로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e90b38b",
   "metadata": {},
   "source": [
    "3. CNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab76a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  합성곱(Convolution) 층과 풀링(Pooling) 층을 정의한 부분입니다. 이를 통해 이미지에서 중요한 특징을 추출하고 \n",
    "#     차원을 축소하여 모델의 복잡성을 줄이면서도 중요한 정보는 유지하는 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15cf5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Pooling 코드 설명:\n",
    "# MaxPooling2D 층:\n",
    "\n",
    "# layers.MaxPooling2D(pool_size=(2, 2)): 2x2 영역에서 최대 풀링을 적용합니다. 이는 입력 이미지의 크기를 1/2로 줄입니다.\n",
    "# Max Pooling은 주어진 영역에서 가장 큰 값을 선택하여 그 값을 해당 영역의 대표 값으로 사용합니다.\n",
    "# 예를 들어, 입력 이미지가 28x28 크기라면 첫 번째 Max Pooling이 적용된 후 출력은 14x14로 줄어듭니다.\n",
    "\n",
    "# 풀링 과정:\n",
    "\n",
    "# 풀링을 통해 이미지의 크기가 축소되면서 중요한 특징을 유지합니다.\n",
    "# 첫 번째 합성곱 이후 Max Pooling을 적용하여 출력의 크기를 줄이고, 두 번째 합성곱 이후에도 동일한 방식으로 크기를 줄입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d0e431",
   "metadata": {},
   "source": [
    "첫 번째 합성곱 및 풀링 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec720ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 층 (Conv2D):\n",
    "# Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)):\n",
    "# 32개의 필터(커널): 입력 이미지에 32개의 필터를 적용하여 32개의 특징 맵을 생성합니다. 각 필터는 이미지에서 서로 다른 패턴을 학습합니다.\n",
    "# (3, 3): 필터의 크기가 3x3임을 의미합니다. 즉, 3x3 크기의 작은 영역에서 지역적인 특징을 추출합니다.\n",
    "# activation='relu': 활성화 함수로 **ReLU(Rectified Linear Unit)**를 사용합니다. 이는 비선형성을 추가하여 더 복잡한 패턴을 학습할 수 있도록 돕습니다.\n",
    "# input_shape=(28, 28, 1): 입력 데이터의 크기입니다. 이 모델은 28x28 크기의 흑백 이미지(채널 수 1)를 입력으로 받습니다.\n",
    "# 풀링 층 (MaxPooling2D):\n",
    "# MaxPooling2D((2, 2)):\n",
    "# 2x2 크기의 풀링: 각 2x2 영역에서 최대값을 선택하여 출력으로 사용합니다. 이를 통해 특징 맵의 크기를 줄여(차원을 축소), 연산량을 줄이고 과적합을 방지하는 역할을 합니다.\n",
    "# 첫 번째 합성곱 층에서 생성된 32개의 특징 맵은 Max Pooling에 의해 크기가 절반으로 줄어듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81047112",
   "metadata": {},
   "source": [
    "두 번째 합성곱 및 풀링 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 층 (Conv2D):\n",
    "# Conv2D(64, (3, 3), activation='relu'):\n",
    "# 64개의 필터(커널): 입력 데이터(첫 번째 합성곱 및 풀링 층의 출력)에 64개의 필터를 적용하여 64개의 특징 맵을 생성합니다. 여기서 필터의 개수를 증가시킴으로써 더 많은 특징을 추출할 수 있습니다.\n",
    "# (3, 3): 필터 크기는 여전히 3x3이며, 이미지의 작은 영역에서 지역적인 특징을 추출합니다.\n",
    "# activation='relu': ReLU 활성화 함수를 사용하여 비선형성을 추가합니다.\n",
    "# 이 층에서는 첫 번째 합성곱과 풀링을 통해 추출된 특징을 더 깊게 분석하여, 더 복잡한 패턴을 학습하게 됩니다.\n",
    "# 풀링 층 (MaxPooling2D):\n",
    "# MaxPooling2D((2, 2)):\n",
    "# 2x2 크기의 풀링: 두 번째 합성곱 층의 출력에 Max Pooling을 적용하여 특징 맵의 크기를 다시 절반으로 줄입니다.\n",
    "# 64개의 특징 맵이 Max Pooling에 의해 다시 축소됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb34b9",
   "metadata": {},
   "source": [
    "세 번째 합성곱 층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 층 (Conv2D):\n",
    "# Conv2D(64, (3, 3), activation='relu'):\n",
    "# 64개의 필터: 두 번째 풀링 층의 출력에 다시 64개의 필터를 적용하여 64개의 특징 맵을 생성합니다.\n",
    "# (3, 3): 필터 크기는 3x3으로 고정되어 있으며, 이 필터는 이전 층에서 추출된 특징을 더욱 세밀하게 분석합니다.\n",
    "# activation='relu': ReLU 활성화 함수를 사용합니다.\n",
    "# 이 층의 역할:\n",
    "# 세 번째 합성곱 층에서는 이미 두 번의 합성곱과 풀링 과정을 통해 추출된 고차원적이고 중요한 특징을 더욱 세밀하게 추출합니다.\n",
    "# 여기서도 ReLU 활성화 함수를 사용하여 비선형성을 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CNN 모델의 주요 구성 요소:\n",
    "# 합성곱 층(Conv2D):\n",
    "\n",
    "# 이미지의 작은 지역에서 중요한 특징을 추출합니다.\n",
    "# 여러 개의 필터를 사용하여 각 필터가 이미지의 다른 특징을 학습할 수 있도록 합니다.\n",
    "# ReLU 활성화 함수를 사용하여 비선형성을 부여하고 복잡한 패턴을 학습할 수 있도록 합니다.\n",
    "# 풀링 층(MaxPooling2D):\n",
    "\n",
    "# 차원 축소: Max Pooling은 합성곱 층의 출력을 축소함으로써 모델의 복잡도를 줄이고 계산 효율성을 높입니다.\n",
    "# 중요 정보 유지: Max Pooling은 각 영역의 최대값을 선택하므로, 중요한 특징은 유지하면서 불필요한 세부 사항은 줄입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81962fc3",
   "metadata": {},
   "source": [
    "#전체 흐름:\n",
    "#첫 번째 합성곱과 풀링 층: 이미지에서 초기 특징을 추출하고, 그 특징을 요약하여 차원을 줄입니다.\n",
    "#두 번째 합성곱과 풀링 층: 더 깊은 특징을 학습하여, 더 복잡한 패턴을 분석하고 차원을 추가로 줄입니다.\n",
    "#세 번째 합성곱 층: 가장 세밀한 특징을 학습하여, 네트워크가 학습할 수 있는 고차원적 정보를 추출합니다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9d0a1",
   "metadata": {},
   "source": [
    "**완전 연결층(Dense Layer)\n",
    "CNN(Convolutional Neural Network) 모델에서 합성곱(Convolution) 층과 풀링(Pooling) 층을 거쳐 추출된 특징을 **완전 연결층(Dense Layer)**에 전달하는 과정을 설명하고 있습니다. \n",
    "이를 통해 최종적으로 모델이 분류 작업을 수행할 수 있게 됩니다. 각각의 층이 어떤 역할을 하는지 단계별로 설명하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228cc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer(은닉층):\n",
    "# 64개의 뉴런을 가진 **완전 연결층(Fully Connected Layer)**입니다. 이 층에서 모델은 추출된 특징을 기반으로 더 복잡한 관계를 학습하게 됩니다.\n",
    "# 뉴런 수(64): 은닉층의 뉴런 개수는 학습해야 할 패턴의 복잡성에 따라 설정되며, 이 경우 64개의 뉴런이 사용됩니다.\n",
    "# activation='relu': 활성화 함수로 **ReLU(Rectified Linear Unit)**를 사용하여 비선형성을 추가합니다. ReLU는 입력값이 양수일 때는 그대로 통과시키고, 음수일 때는 0으로 만듭니다. 이를 통해 뉴런이 학습할 수 있는 패턴의 복잡성을 증가시킵니다.\n",
    "# 역할:\n",
    "# 완전 연결층은 Flatten 층을 통해 전달된 데이터를 입력으로 받아, 각 뉴런이 이전 층의 모든 출력을 연결하여 복잡한 패턴을 학습합니다.\n",
    "# 이 은닉층은 학습된 특징을 기반으로 최종 출력층에 전달할 데이터를 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d391c7",
   "metadata": {},
   "source": [
    "Dense Layer(출력층):\n",
    "10개의 뉴런을 가진 완전 연결 출력층입니다. 여기서 10개의 뉴런은 **MNIST 데이터셋의 10개의 클래스(숫자 0~9)**를 나타냅니다.\n",
    "activation='softmax': Softmax 활성화 함수를 사용합니다. Softmax는 각 클래스에 대한 확률을 출력하며, 출력 값은 0과 1 사이의 값이고, 모든 출력 값의 합이 1이 되도록 만듭니다. 즉, 각 뉴런은 특정 클래스에 속할 확률을 나타냅니다.\n",
    "역할:\n",
    "이 출력층은 분류 작업을 수행하는 층으로, 모델이 이미지가 어떤 숫자(0~9)에 해당하는지를 예측할 수 있도록 합니다.\n",
    "Softmax는 분류 문제에서 각 클래스에 대한 확률을 계산하는데 적합한 활성화 함수입니다. 이 층은 최종적으로 가장 높은 확률 값을 가진 뉴런을 선택하여, 예측된 클래스를 결정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef5bee",
   "metadata": {},
   "source": [
    "4. 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac699010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델이 학습할 방법, 즉 최적화 알고리즘(optimizer), 손실 함수(loss function), 그리고 **평가지표(metrics)**를 설정하게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60742013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer='adam' - 최적화 알고리즘\n",
    "# optimizer='adam': 모델의 가중치를 어떻게 업데이트할지를 결정하는 최적화 알고리즘을 설정합니다. \n",
    "# 여기서 사용된 Adam(Adaptive Moment Estimation) 옵티마이저는 딥러닝에서 가장 널리 사용되는 최적화 알고리즘 중 하나입니다.\n",
    "# Adam 옵티마이저의 특징:\n",
    "# 학습률 자동 조정: Adam은 학습률을 자동으로 조정해주므로, 복잡한 데이터에서도 잘 작동합니다.\n",
    "# 모멘텀과 적응형 학습률을 결합하여 학습의 효율성을 높입니다.\n",
    "# 모멘텀은 가중치 업데이트의 방향을 가속화하여 더 빠르게 수렴하도록 돕습니다.\n",
    "# 적응형 학습률은 각 가중치마다 학습률을 조정하여 가중치별로 최적의 학습률을 적용합니다.\n",
    "# 장점: 학습률을 수동으로 조정할 필요가 적고, 불안정한 경사에서도 잘 작동합니다. 특히, 이미지 분류 작업과 같은 문제에서 빠르고 안정적인 학습을 제공합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768efe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. loss='sparse_categorical_crossentropy' - 손실 함수\n",
    "# loss='sparse_categorical_crossentropy': 손실 함수는 모델이 얼마나 잘못 예측했는지를 측정하는 함수입니다. CNN 모델이 최적화 과정에서 이 손실 값을 최소화하려고 가중치를 조정하게 됩니다.\n",
    "# Sparse Categorical Crossentropy:\n",
    "# 사용 이유: 이 손실 함수는 다중 클래스 분류 문제에서 사용됩니다. MNIST 데이터셋은 숫자 0부터 9까지의 10개의 클래스를 분류하는 문제이므로, 다중 클래스 분류에 적합한 손실 함수가 필요합니다.\n",
    "# sparse_categorical_crossentropy는 **정수형 레이블(예: 0, 1, 2, ... 9)**을 사용합니다. 정수형 레이블은 각 클래스에 고유한 정수값을 매기며, one-hot encoding을 하지 않고도 사용할 수 있습니다.\n",
    "# 손실 계산 방식: 각 예측값(모델의 출력 확률 분포)과 실제 레이블 간의 차이를 측정합니다. 손실 값이 작을수록 모델의 예측이 실제 값에 가까운 것이며, 이 손실을 최소화하는 방향으로 모델을 학습시킵니다.\n",
    "# Crossentropy의 의미:\n",
    "# **Crossentropy(교차 엔트로피)**는 분류 문제에서 예측 확률 분포와 실제 레이블의 차이를 측정하는 방법입니다.\n",
    "# 예측 확률이 정답에 가까울수록 손실이 작아지고, 예측이 틀리면 손실이 커집니다.\n",
    "# CNN에서 이 손실 함수를 통해 출력층의 Softmax 함수로 계산된 확률 분포와 실제 정답 레이블 간의 차이를 계산하여 학습을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. metrics=['accuracy'] - 평가지표\n",
    "# metrics=['accuracy']: 모델을 학습하는 동안 **정확도(accuracy)**를 평가하기 위한 지표를 설정합니다.\n",
    "# Accuracy:\n",
    "# 정확도(accuracy)는 분류 문제에서 가장 일반적으로 사용되는 평가 지표 중 하나입니다.\n",
    "# 정확도 계산 방식: 전체 샘플 중 모델이 올바르게 예측한 샘플의 비율을 나타냅니다. \n",
    "# 즉, **(올바르게 예측한 샘플 수 / 전체 샘플 수)**로 계산됩니다.\n",
    "# 사용 이유: MNIST와 같은 다중 클래스 분류 문제에서, 모델이 얼마나 정확하게 숫자를 분류했는지 확인하기 위해 정확도를 평가 지표로 설정합니다.\n",
    "# 모델이 학습되는 동안 각 에포크마다 정확도가 계산되어 출력됩니다. \n",
    "# 이를 통해 모델이 얼마나 잘 학습하고 있는지 실시간으로 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc8f9c",
   "metadata": {},
   "source": [
    "5. 모델 학습: model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     model.fit()은 모델을 학습시키는 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505f6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 파라미터:\n",
    "# x_train: 학습에 사용되는 입력 데이터(훈련 데이터).\n",
    "# MNIST 데이터셋의 경우, 손글씨 숫자 이미지(28x28 크기)가 훈련 데이터로 사용됩니다.\n",
    "# y_train: 학습에 사용되는 정답 레이블.\n",
    "# 각 이미지에 대응하는 실제 레이블(0부터 9까지의 숫자)을 의미합니다.\n",
    "# epochs=5: 전체 데이터셋을 몇 번 반복하여 학습할 것인지 결정하는 에포크(epoch) 수를 나타냅니다.\n",
    "# 에포크는 모델이 전체 훈련 데이터셋을 한 번 학습하는 과정을 의미합니다.\n",
    "# 여기서는 5번의 에포크 동안 학습이 진행됩니다. 즉, 전체 훈련 데이터를 5번 반복해서 모델에 학습시킵니다.\n",
    "# model.fit()의 역할:\n",
    "# 훈련 데이터(x_train, y_train)를 사용하여 모델을 학습시킵니다.\n",
    "# 각 에포크마다 모델은 데이터셋의 샘플을 사용하여 가중치를 업데이트하고, 손실 함수와 정확도 지표를 사용해 성능을 개선합니다.\n",
    "# 5번의 에포크 동안 학습이 이루어지며, 매 에포크마다 손실 값과 정확도를 보고할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d1136",
   "metadata": {},
   "source": [
    "6. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate()는 학습된 모델의 성능을 테스트 데이터셋으로 평가하는 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 파라미터:\n",
    "# x_test: 모델이 학습된 후 성능을 평가할 때 사용하는 테스트 데이터.\n",
    "# 테스트 데이터는 모델이 학습하지 않은 데이터이므로, 모델이 새로운 데이터에서 얼마나 잘 작동하는지 평가할 수 있습니다.\n",
    "\n",
    "# y_test: 테스트 데이터에 대한 정답 레이블.\n",
    "# 테스트 이미지에 대응하는 실제 숫자 레이블(0~9)입니다. 모델의 예측 값과 이 실제 레이블을 비교하여 성능을 평가합니다.\n",
    "\n",
    "# model.evaluate()의 역할:\n",
    "# 학습된 모델을 테스트 데이터로 평가합니다. 학습 데이터가 아닌, 모델이 한 번도 본 적 없는 데이터로 모델 성능을 확인합니다.\n",
    "\n",
    "# **손실 값(test_loss)**과 **정확도(test_acc)**를 계산하여 반환합니다.\n",
    "# 손실 값은 모델의 예측 값과 실제 정답 값의 차이를 나타내며, 값이 낮을수록 모델의 예측이 실제 값에 가깝다는 것을 의미합니다.\n",
    "# 정확도는 테스트 데이터셋에서 모델이 얼마나 정확하게 예측했는지를 나타내며, 올바르게 예측한 샘플의 비율을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91095b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.8949 - loss: 0.3375\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9844 - loss: 0.0502\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9882 - loss: 0.0363\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9917 - loss: 0.0283\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9941 - loss: 0.0184\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0469\n",
      "테스트 정확도: 0.9896000027656555\n"
     ]
    }
   ],
   "source": [
    "# 3. CNN 모델 정의\n",
    "model = models.Sequential([\n",
    "    # 첫 번째 합성곱 및 풀링 층\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # 합성곱 (3x3 필터, 32개)\n",
    "    layers.MaxPooling2D((2, 2)),                                             # Max Pooling (2x2 크기)\n",
    "    \n",
    "    # 두 번째 합성곱 및 풀링 층\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),                           # 합성곱 (3x3 필터, 64개)\n",
    "    layers.MaxPooling2D((2, 2)),                                             # Max Pooling (2x2 크기)\n",
    "    \n",
    "    # 세 번째 합성곱 및 풀링 층\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),                           # 합성곱 (3x3 필터, 64개)\n",
    "\n",
    "    # 완전 연결층(Dense)을 사용하기 위해 Flatten\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),    # 은닉층\n",
    "    layers.Dense(10, activation='softmax')  # 출력층 (10개의 클래스)\n",
    "])\n",
    "\n",
    "# 4. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. 모델 학습\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# 6. 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'테스트 정확도: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 해석\n",
    "\n",
    "# test_acc: 모델이 테스트 데이터셋에서 얼마나 정확한지를 나타냅니다. \n",
    "#     여기서 계산된 테스트 정확도는 학습되지 않은 데이터에서 모델이 얼마나 잘 작동하는지를 보여줍니다.\n",
    "#     이 출력은 모델이 테스트 데이터셋에서 약 98%의 정확도로 숫자를 분류했다는 의미입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd0c1d",
   "metadata": {},
   "source": [
    "## Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8897ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Average Pooling(평균 풀링): 영역 내에서 평균 값을 계산하여 그 영역을 대표합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2832ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 설명:\n",
    "# 데이터 준비:\n",
    "\n",
    "# MNIST 데이터셋을 불러오고 28x28 크기의 흑백 이미지로 변환한 후, CNN 모델에 입력할 수 있도록 reshape합니다.\n",
    "# 0~1 사이로 픽셀 값을 정규화하여 학습이 더 원활하게 이루어지도록 합니다.\n",
    "# 모델 정의:\n",
    "\n",
    "# Conv2D: 합성곱 층으로 32개의 필터(3x3)를 사용해 이미지의 특징을 추출합니다.\n",
    "# AveragePooling2D: 합성곱 층 후에 2x2 크기의 평균 풀링을 적용하여 차원을 축소하고 특징을 요약합니다.\n",
    "# 두 번째 합성곱 층과 두 번째 평균 풀링을 사용하여 추가로 이미지의 특징을 추출하고 차원을 축소합니다.\n",
    "# Flatten: 2D 데이터를 1D로 펼쳐서 완전 연결층(Dense)으로 입력합니다.\n",
    "# 마지막 Dense 층에서 10개의 클래스(0-9) 중 하나를 예측하기 위해 softmax를 사용합니다.\n",
    "# 모델 학습 및 평가:\n",
    "\n",
    "# 모델은 5번의 에포크 동안 학습되며, 학습이 완료된 후 테스트 데이터에서 평가합니다.\n",
    "# 최종적으로 테스트 정확도를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100acd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - accuracy: 0.8700 - loss: 0.4212\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.9815 - loss: 0.0622\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.9879 - loss: 0.0392\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.9903 - loss: 0.0292\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.9920 - loss: 0.0244\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0382\n",
      "테스트 정확도: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 1. 데이터 준비 (MNIST 데이터셋 로드)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 2. 데이터 전처리 (reshape 및 정규화)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # (60000, 28, 28, 1)로 변환\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)    # (10000, 28, 28, 1)로 변환\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # 0~1로 정규화\n",
    "\n",
    "# 3. CNN 모델 정의 (Average Pooling 적용)\n",
    "model = models.Sequential([\n",
    "    # 첫 번째 합성곱 및 풀링 층\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # 합성곱 (3x3 필터, 32개)\n",
    "    layers.AveragePooling2D((2, 2)),                                         # Average Pooling (2x2 크기)\n",
    "    \n",
    "    # 두 번째 합성곱 및 풀링 층\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),                           # 합성곱 (3x3 필터, 64개)\n",
    "    layers.AveragePooling2D((2, 2)),                                         # Average Pooling (2x2 크기)\n",
    "    \n",
    "    # 세 번째 합성곱 및 풀링 층\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),                           # 합성곱 (3x3 필터, 64개)\n",
    "\n",
    "    # 완전 연결층(Dense)을 사용하기 위해 Flatten\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),    # 은닉층\n",
    "    layers.Dense(10, activation='softmax')  # 출력층 (10개의 클래스)\n",
    "])\n",
    "\n",
    "# 4. 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. 모델 학습\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# 6. 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'테스트 정확도: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefb37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d00d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layers.AveragePooling2D((2, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f5de53",
   "metadata": {},
   "source": [
    "# 가중치 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f009f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# He 초기화와 Xavier 초기화는 신경망의 가중치를 초기화하는 두 가지 중요한 방법으로, \n",
    "# 각각의 방법은 심층 신경망의 학습을 안정화하고 성능을 개선하기 위해 설계되었습니다. \n",
    "# 신경망을 훈련할 때 가중치를 적절하게 초기화하는 것은 기울기 소실(vanishing gradients) 또는 기울기 폭발(exploding gradients) 문제를 줄여주고, 빠르고 안정적인 학습을 가능하게 합니다. 이 두 방법은 활성화 함수의 특성을 고려하여 적절한 가중치 분포를 설정하는 방식으로 작동합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0071902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Xavier 초기화 (Glorot 초기화)\n",
    "# Sigmoid 또는 tanh와 같은 대칭적인 활성화 함수를 사용하는 신경망에서 주로 사용됩니다. \n",
    "# 이 방법은 2010년에 Xavier Glorot와 Yoshua Bengio에 의해 제안되었습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. He 초기화 (Kaiming 초기화)\n",
    "# **He 초기화(Kaiming Initialization)**는 ReLU와 같은 비대칭 활성화 함수를 사용하는 신경망에서 주로 사용됩니다. 이는 2015년에 Kaiming He와 그의 연구팀에 의해 제안되었으며, ReLU와 그 변형 함수들에서 더 안정적인 학습을 가능하게 해줍니다.\n",
    "\n",
    "# 기본 아이디어:\n",
    "# ReLU 함수는 음수 값을 0으로 만들어버리기 때문에, 활성화 함수로 인해 뉴런이 활성화되지 않는 죽은 뉴런(Dead Neuron) 문제나 기울기 소실 문제가 발생할 수 있습니다. He 초기화는 이러한 문제를 완화하기 위해 설계되었으며, 주로 입력 노드 수 \n",
    "# 𝑛in​에만 기반하여 가중치를 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier vs. He 초기화: 차이점\n",
    "# Xavier 초기화는 입력 노드 수와 출력 노드 수의 평균을 기반으로 가중치를 초기화하며, Sigmoid나 tanh와 같은 대칭 활성화 함수에 적합합니다.\n",
    "# He 초기화는 입력 노드 수를 기반으로 가중치를 초기화하며, ReLU나 Leaky ReLU와 같은 비대칭 활성화 함수에 적합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfed76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터셋을 사용하여 He 초기화와 Xavier 초기화를 적용한 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 설명:\n",
    "# He 초기화: 첫 번째 은닉층에서 initializers.HeNormal()을 사용하여 He 초기화를 적용합니다. \n",
    "# 이는 ReLU 활성화 함수와 잘 어울립니다.\n",
    "\n",
    "# Xavier 초기화: 두 번째 은닉층에서 initializers.GlorotNormal()을 사용하여 Xavier 초기화를 적용합니다.\n",
    "# 모델 학습 및 평가: MNIST 데이터셋에서 5번의 에포크 동안 모델을 학습하고, 테스트 데이터에서 정확도를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, initializers\n",
    "\n",
    "# MNIST 데이터셋 로드\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터 전처리 (정규화)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# 모델 정의 (He 초기화와 Xavier 초기화를 사용)\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),     # 입력층 (28x28 이미지 평탄화)\n",
    "    layers.Dense(128, activation='relu',      # 은닉층 (He 초기화 사용)\n",
    "                 kernel_initializer=initializers.HeNormal()),  \n",
    "    layers.Dense(64, activation='relu',       # 은닉층 (Xavier 초기화 사용)\n",
    "                 kernel_initializer=initializers.GlorotNormal()),  \n",
    "    layers.Dense(10, activation='softmax')    # 출력층\n",
    "])\n",
    "\n",
    "# 모델 컴파일 (Adam 옵티마이저와 크로스엔트로피 손실함수)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습 (5 에포크 동안)\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'테스트 정확도: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2211323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4754f62",
   "metadata": {},
   "source": [
    "참고사항"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185e154",
   "metadata": {},
   "source": [
    "RGB 색상 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c1d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB 색상 이미지를 CNN 모델에 사용할 수 있도록 전처리하는 Python 코드를 작성해드리겠습니다. \n",
    "# 이 코드는 TensorFlow와 Keras를 사용하여 간단한 CNN 모델을 구축하고 RGB 이미지를 입력으로 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba970ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RGB 색상을 변화시켜 시각적으로 보여주는 함수 정의\n",
    "def display_color_changes(rgb_values):\n",
    "    fig, axes = plt.subplots(1, len(rgb_values), figsize=(15, 5))\n",
    "    \n",
    "    for ax, rgb in zip(axes, rgb_values):\n",
    "        # 각 RGB 값을 [0, 1] 범위로 정규화하여 색상을 생성\n",
    "        ax.imshow(np.ones((100, 100, 3)) * np.array(rgb)/255)\n",
    "        # 제목에 RGB 값을 표시\n",
    "        ax.set_title(f'RGB: {rgb}')\n",
    "        ax.axis('off')  # 축을 끔\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 다양한 RGB 값 리스트\n",
    "rgb_values = [\n",
    "        [255, 255, 0], # 노란색\n",
    "    [0, 255, 255], # 청록색\n",
    "    [255, 0, 255], # 자홍색\n",
    "    [128, 128, 128], # 회색\n",
    "    [0, 0, 0], # 검은색\n",
    "    [255, 255, 255]  # 흰색\n",
    "]\n",
    "\n",
    "# 함수 호출\n",
    "display_color_changes(rgb_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69694f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
