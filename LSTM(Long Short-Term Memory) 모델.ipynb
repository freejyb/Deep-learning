{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM(Long Short-Term Memory) 모델을 구현하는 예제 코드입니다. \n",
    "# 이 코드는 IMDB 영화 리뷰 감정 분석 데이터셋을 사용하여, LSTM 모델을 학습하고 감정을 예측하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b2d16",
   "metadata": {},
   "source": [
    "# 준비단계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99d43d",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4cf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1c65f",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678d9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "max_features = 10000  # 사용할 단어의 최대 개수 (상위 10,000개 단어 사용)\n",
    "maxlen = 100  # 각 리뷰의 최대 길이 (100개의 단어로 제한)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b976e2",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fac8428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리:\n",
    "\n",
    "# imdb.load_data() 함수를 사용해 IMDB 영화 리뷰 데이터셋을 로드합니다. \n",
    "#  이 데이터셋은 이진 분류 문제로, 영화 리뷰가 긍정인지 부정인지 예측하는 문제입니다.\n",
    "# 각 리뷰는 단어의 시퀀스로 표현되며, 최대 10,000개의 상위 단어만 사용합니다.\n",
    "# 리뷰의 길이가 다르므로, pad_sequences를 사용하여 각 리뷰를 100개의 단어로 맞춥니다. \n",
    "# 길이가 100보다 짧은 리뷰는 패딩을 추가하고, 길면 자릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4df5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDB 데이터셋 로드 (훈련 데이터와 테스트 데이터 분리)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bb47f",
   "metadata": {},
   "source": [
    "## 시퀀스 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faf49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 패딩 (각 리뷰의 길이를 동일하게 100으로 맞춤)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91c4030",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307609e",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4489c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의:\n",
    "\n",
    "# Embedding 층: 입력 단어를 고차원 밀집 벡터로 변환합니다. 입력 단어의 개수는 최대 10,000개이고, 각 단어는 32차원의 벡터로 변환됩니다.\n",
    "# LSTM 층: 100개의 유닛을 가진 LSTM(Long Short-Term Memory) 층입니다. return_sequences=False로 설정하여, 마지막 출력만 반환하여 다음 층으로 전달합니다.\n",
    "# 출력층(Dense): 감정이 긍정인지 부정인지 예측하는 이진 분류 문제이므로, 1개의 노드와 시그모이드(Sigmoid) 활성화 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2b704f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding 층: 단어를 밀집 벡터로 변환, 입력 차원은 max_features, 출력 차원은 32\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
    "\n",
    "# LSTM 층: 100개의 유닛을 사용\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "\n",
    "# 출력층 (Dense): 1개의 노드, 활성화 함수: Sigmoid (이진 분류 문제이므로)\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e151dce0",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0933b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수로 binary_crossentropy를 사용하며, 이진 분류 문제에 적합한 손실 함수입니다.\n",
    "# 최적화 방법으로 Adam을 사용하여 경사 하강법을 최적화합니다.\n",
    "# 성능 평가 지표로 **accuracy(정확도)**를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7081eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 (손실 함수: Binary Crossentropy, 최적화 방법: Adam, 평가지표: Accuracy)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defe04df",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1efe40b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 에포크 동안 학습하며, 배치 크기 64로 설정하여 학습을 진행합니다.\n",
    "# 학습 중간에 테스트 데이터를 사용해 검증도 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c7b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 154ms/step - accuracy: 0.6519 - loss: 0.5841 - val_accuracy: 0.8492 - val_loss: 0.3445\n",
      "Epoch 2/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 192ms/step - accuracy: 0.8890 - loss: 0.2799 - val_accuracy: 0.8513 - val_loss: 0.3435\n",
      "Epoch 3/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 165ms/step - accuracy: 0.9175 - loss: 0.2127 - val_accuracy: 0.8416 - val_loss: 0.3910\n",
      "Epoch 4/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 157ms/step - accuracy: 0.9373 - loss: 0.1657 - val_accuracy: 0.8419 - val_loss: 0.4042\n",
      "Epoch 5/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 156ms/step - accuracy: 0.9570 - loss: 0.1261 - val_accuracy: 0.8282 - val_loss: 0.5269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630127f",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d09e2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습이 완료되면 테스트 데이터셋에서 모델 성능을 평가하고 정확도(accuracy)를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b3ea33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.8276 - loss: 0.5309\n",
      "Test Accuracy: 82.82%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a1929",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a40991bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 사용해 테스트 데이터에 대한 예측값을 생성합니다.\n",
    "# 결과 출력\n",
    "# 모델 학습이 완료되면 다음과 같은 정보가 출력됩니다:\n",
    "\n",
    "# Test Accuracy: 테스트 데이터셋에서의 정확도를 퍼센트로 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "192b2e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측 (테스트 데이터에 대한 예측)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468096c5",
   "metadata": {},
   "source": [
    "# 종합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084576a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "max_features = 10000  # 사용할 단어의 최대 개수 (상위 10,000개 단어 사용)\n",
    "maxlen = 100  # 각 리뷰의 최대 길이 (100개의 단어로 제한)\n",
    "\n",
    "# IMDB 데이터셋 로드 (훈련 데이터와 테스트 데이터 분리)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 시퀀스 패딩 (각 리뷰의 길이를 동일하게 100으로 맞춤)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding 층: 단어를 밀집 벡터로 변환, 입력 차원은 max_features, 출력 차원은 32\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
    "\n",
    "# LSTM 층: 100개의 유닛을 사용\n",
    "model.add(LSTM(100, return_sequences=False))\n",
    "\n",
    "# 출력층 (Dense): 1개의 노드, 활성화 함수: Sigmoid (이진 분류 문제이므로)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일 (손실 함수: Binary Crossentropy, 최적화 방법: Adam, 평가지표: Accuracy)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 예측 (테스트 데이터에 대한 예측)\n",
    "predictions = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
