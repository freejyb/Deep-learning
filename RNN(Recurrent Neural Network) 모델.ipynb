{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ab8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN(Recurrent Neural Network) 모델을 구현하는 예제 코드입니다. \n",
    "# 이 코드는 IMDB 영화 리뷰 감정 분석 데이터셋을 사용하여, RNN을 학습하고 감정을 예측하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e3e59",
   "metadata": {},
   "source": [
    "# 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0257943",
   "metadata": {},
   "source": [
    "## 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71a81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2100993",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3b50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000  # 사용할 단어의 최대 개수 (상위 10,000개 단어 사용)\n",
    "maxlen = 100  # 각 리뷰의 최대 길이 (100개의 단어로 제한)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69bdc53",
   "metadata": {},
   "source": [
    "## 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdb.load_data() 함수를 사용해 IMDB 영화 리뷰 데이터셋을 로드합니다. \n",
    "# 이 데이터셋은 이진 분류 문제로, 영화 리뷰가 긍정인지 부정인지 예측하는 문제입니다.\n",
    "# 각 리뷰는 단어의 시퀀스로 표현되며, 최대 10,000개의 상위 단어만 사용합니다.\n",
    "# 리뷰 길이가 다르므로, pad_sequences를 사용하여 각 리뷰를 100개의 단어로 맞춥니다. \n",
    "# 길이가 100보다 짧은 리뷰는 패딩을 추가하고, 길면 자릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c95548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터셋 로드 (훈련 데이터와 테스트 데이터 분리)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 시퀀스 패딩 (각 리뷰의 길이를 동일하게 100으로 맞춤)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e581569",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b995caf",
   "metadata": {},
   "source": [
    "## RNN 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b0df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 층: 입력 단어를 고차원 밀집 벡터로 변환합니다. 입력 단어의 개수는 최대 10,000개이고, 각 단어는 32차원의 벡터로 변환됩니다.\n",
    "# SimpleRNN 층: RNN 구조를 사용하여 시퀀스 데이터를 처리합니다. 이 층은 32개의 유닛을 가집니다.\n",
    "# 출력층(Dense): 감정이 긍정인지 부정인지 예측하는 이진 분류 문제이므로, 1개의 노드와 시그모이드(Sigmoid) 활성화 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84de02fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jyb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델 정의\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding 층: 단어를 밀집 벡터로 변환, 입력 차원은 max_features, 출력 차원은 32\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
    "\n",
    "# Simple RNN 층: 32개의 유닛\n",
    "model.add(SimpleRNN(32))\n",
    "\n",
    "# 출력층 (Dense): 1개의 노드, 활성화 함수: Sigmoid (이진 분류 문제이므로)\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d897838",
   "metadata": {},
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9b8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수로 binary_crossentropy를 사용하며, 이진 분류 문제에 적합한 손실 함수입니다.\n",
    "# 최적화 방법으로 Adam을 사용하여 경사 하강법을 최적화합니다.\n",
    "# 성능 평가 지표로 **accuracy(정확도)**를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89544bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28616722",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6554d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 에포크 동안 학습하며, 배치 크기 128로 설정하여 학습을 진행합니다.\n",
    "# 학습 중간에 테스트 데이터를 사용해 검증도 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc52306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - accuracy: 0.6137 - loss: 0.6350 - val_accuracy: 0.8168 - val_loss: 0.4096\n",
      "Epoch 2/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.8688 - loss: 0.3222 - val_accuracy: 0.8437 - val_loss: 0.3647\n",
      "Epoch 3/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9174 - loss: 0.2220 - val_accuracy: 0.8268 - val_loss: 0.4295\n",
      "Epoch 4/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9491 - loss: 0.1532 - val_accuracy: 0.8286 - val_loss: 0.4569\n",
      "Epoch 5/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.9758 - loss: 0.0859 - val_accuracy: 0.8282 - val_loss: 0.4922\n",
      "Epoch 6/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9885 - loss: 0.0445 - val_accuracy: 0.8232 - val_loss: 0.5864\n",
      "Epoch 7/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9923 - loss: 0.0321 - val_accuracy: 0.8055 - val_loss: 0.6069\n",
      "Epoch 8/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.9947 - loss: 0.0231 - val_accuracy: 0.8208 - val_loss: 0.6781\n",
      "Epoch 9/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9976 - loss: 0.0127 - val_accuracy: 0.8177 - val_loss: 0.7252\n",
      "Epoch 10/10\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.9987 - loss: 0.0086 - val_accuracy: 0.8204 - val_loss: 0.7837\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 (손실 함수: Binary Crossentropy, 최적화 방법: Adam, 평가지표: Accuracy)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c08786",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378e97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습이 완료되면 테스트 데이터셋에서 모델 성능을 평가하고 **정확도(accuracy)**를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0913a1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8181 - loss: 0.7930\n",
      "Test Accuracy: 82.04%\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f55f3b",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f3ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델을 사용해 테스트 데이터에 대한 예측값을 생성합니다.\n",
    "# 결과 출력\n",
    "# 모델 학습이 완료되면 다음과 같은 정보가 출력됩니다:\n",
    "\n",
    "# Test Accuracy: 테스트 데이터셋에서의 정확도를 퍼센트로 표시합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "040afabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# 예측 (테스트 데이터에 대한 예측)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec6782",
   "metadata": {},
   "source": [
    "# 종합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5365eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "max_features = 10000  # 사용할 단어의 최대 개수 (상위 10,000개 단어 사용)\n",
    "maxlen = 100  # 각 리뷰의 최대 길이 (100개의 단어로 제한)\n",
    "\n",
    "# IMDB 데이터셋 로드 (훈련 데이터와 테스트 데이터 분리)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 시퀀스 패딩 (각 리뷰의 길이를 동일하게 100으로 맞춤)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# RNN 모델 정의\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding 층: 단어를 밀집 벡터로 변환, 입력 차원은 max_features, 출력 차원은 32\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
    "\n",
    "# Simple RNN 층: 32개의 유닛\n",
    "model.add(SimpleRNN(32))\n",
    "\n",
    "# 출력층 (Dense): 1개의 노드, 활성화 함수: Sigmoid (이진 분류 문제이므로)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일 (손실 함수: Binary Crossentropy, 최적화 방법: Adam, 평가지표: Accuracy)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 예측 (테스트 데이터에 대한 예측)\n",
    "predictions = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
