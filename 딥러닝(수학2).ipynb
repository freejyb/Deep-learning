{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b64210-b6b7-464a-b4b1-cd34137c3010",
   "metadata": {},
   "source": [
    "# 1.  고유값(Eigenvalue)과 고유벡터(Eigenvector) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e150c94-73f8-4ed4-ab74-d66a5bff780a",
   "metadata": {},
   "source": [
    "고유값(Eigenvalue): \n",
    "\n",
    "행렬 𝐴의 변환에 의해 벡터의 방향이 변하지 않는 경우, 그 벡터는 고유벡터(eigenvector)이며, 이 때의 스칼라 값 𝜆는 고유값입니다,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62396b-10a1-4c75-9754-da1d25b0f68b",
   "metadata": {},
   "source": [
    "### Av=λv 식을 검증 ( 𝜆는 고유값 , v : 고유벡터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5fb990-83ff-4214-a21d-702c3e405e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 설명\n",
    "\n",
    "# np.array를 사용해 행렬 𝐴를 정의합니다.\n",
    "\n",
    "# np.linalg.eig() 함수를 사용해 행렬 𝐴의 고유값과 고유벡터를 계산합니다.\n",
    "    \n",
    "# eigenvalues는 고유값이 들어 있는 배열입니다.\n",
    "\n",
    "# eigenvectors는 각 고유값에 대응하는 고유벡터가 열(column) 형태로 들어 있는 행렬입니다.\n",
    "\n",
    "# 고유값과 고유벡터를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677368e9-1efa-4dcd-8600-519ae5069dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유값 (Eigenvalues):\n",
      "[5. 2.]\n",
      "\n",
      "고유벡터 (Eigenvectors):\n",
      "[[ 0.70710678 -0.4472136 ]\n",
      " [ 0.70710678  0.89442719]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 행렬 A 정의\n",
    "A = np.array([[4, 1],\n",
    "              [2, 3]])\n",
    "\n",
    "# 고유값과 고유벡터 계산\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"고유값 (Eigenvalues):\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\n고유벡터 (Eigenvectors):\")\n",
    "print(eigenvectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21375e08-a246-448d-95d3-a2b9a7f9f8d3",
   "metadata": {},
   "source": [
    "해석\n",
    "고유값 𝜆1=5, 𝜆2=2입니다.\n",
    "    \n",
    "첫 번째 고유값 𝜆1=5에 대응하는 고유벡터는 [0.707,0.707]입니다.\n",
    "    \n",
    "두 번째 고유값 𝜆2=2에 대응하는 고유벡터는 [−0.447,0.894]입니다.\n",
    "    \n",
    "이 예제는 행렬이 벡터를 변환할 때, 고유벡터의 방향은 변하지 않고, 스칼라 배만 된다는 것을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92268d03-988c-4e5d-b6f6-c3a18d17e052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e94d7a-d842-4b63-8edd-1f935f5a6b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# . 코드 설명\n",
    "\n",
    "# 행렬 정의: A는 2 × 2 크기의 행렬입니다.\n",
    "# 고유값과 고유벡터 계산: np.linalg.eig() 함수를 사용하여 고유값과 고유벡터를 계산합니다.\n",
    "\n",
    "# eigenvalues는 고유값을 포함하는 배열입니다.\n",
    "# eigenvectors는 각 고유값에 대응하는 고유벡터를 열(column)로 가지는 행렬입니다.\n",
    "# . 코드 설명\n",
    "# Av=λv 식을 검증하기 위해, np.dot()을 사용하여 행렬-벡터 곱셈을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccaa44b-9680-4e11-8ed1-793099d06305",
   "metadata": {},
   "source": [
    "### Av=λv 식을 검증 ( 𝜆는 고유값 , v : 고유벡터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e02918a-bb62-488b-a896-44988e78a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 A:\n",
      "[[4 1]\n",
      " [2 3]]\n",
      "\n",
      "고유값 (Eigenvalues):\n",
      "[5. 2.]\n",
      "\n",
      "고유벡터 (Eigenvectors):\n",
      "[[ 0.70710678 -0.4472136 ]\n",
      " [ 0.70710678  0.89442719]]\n",
      "\n",
      "검증 (고유값 λ_1 = 5.0):\n",
      "좌변 (A * v): [3.53553391 3.53553391]\n",
      "우변 (λ * v): [3.53553391 3.53553391]\n",
      "\n",
      "검증 (고유값 λ_2 = 2.0):\n",
      "좌변 (A * v): [-0.89442719  1.78885438]\n",
      "우변 (λ * v): [-0.89442719  1.78885438]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 행렬 A 정의\n",
    "A = np.array([[4, 1],\n",
    "              [2, 3]])\n",
    "\n",
    "# 고유값과 고유벡터 계산\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "# 고유값 및 고유벡터 출력\n",
    "print(\"행렬 A:\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n고유값 (Eigenvalues):\")\n",
    "print(eigenvalues)\n",
    "\n",
    "print(\"\\n고유벡터 (Eigenvectors):\")\n",
    "print(eigenvectors)\n",
    "\n",
    "# 행렬 방정식 A * v = lambda * v 검증\n",
    "for i in range(len(eigenvalues)):\n",
    "    lambda_i = eigenvalues[i]\n",
    "    v_i = eigenvectors[:, i]\n",
    "    \n",
    "    # 좌변: A * v\n",
    "    left_side = np.dot(A, v_i)\n",
    "    # 우변: lambda * v\n",
    "    right_side = lambda_i * v_i\n",
    "    \n",
    "    print(f\"\\n검증 (고유값 λ_{i+1} = {lambda_i}):\")\n",
    "    print(\"좌변 (A * v):\", left_side)\n",
    "    print(\"우변 (λ * v):\", right_side)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027cbb9f-a791-4799-9f21-410d52ed55cd",
   "metadata": {},
   "source": [
    "# 2. 문장 유사도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb75b71-2169-443c-85c4-8f13540aa619",
   "metadata": {},
   "source": [
    "코사인 유사도와 유클리드 거리를 계산하기 위해, 먼저 텍스트를 벡터로 변환해야 합니다. \n",
    "\n",
    "이를 위해 TF-IDF (Term Frequency-Inverse Document Frequency) 기법을 사용할 수 있습니다. \n",
    "\n",
    "이 방법은 단어의 빈도수를 고려하면서, 문서 간의 차이를 잘 반영할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e169cf-a904-4083-a01a-ca86b2ee350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 설명\n",
    "# 문장 정의: 세 개의 문장을 정의합니다. 여기서는 3개 문장을 입력 함.\n",
    "\n",
    "# TF-IDF 벡터화: TfidfVectorizer를 사용하여 문장들을 벡터로 변환합니다.\n",
    "# 각 문장은 TF-IDF 값을 가지는 벡터로 변환됩니다.\n",
    "\n",
    "# 코사인 유사도 계산: cosine_similarity() 함수를 사용해 코사인 유사도를 계산합니다.\n",
    "# 코사인 유사도 값은 0에서 1 사이로 나타나며, 값이 클수록 두 문장이 유사합니다.\n",
    "\n",
    "# 유클리드 거리 계산: euclidean_distances() 함수를 사용해 유클리드 거리를 계산합니다.\n",
    "# 유클리드 거리는 두 벡터 간의 거리로, 값이 작을수록 두 문장이 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac8b564-eb79-46f0-8fec-faae0cce2188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 벡터화 결과:\n",
      "[[0.         0.         0.         0.41329182 0.         0.\n",
      "  0.         0.         0.         0.41329182 0.         0.\n",
      "  0.24409681 0.         0.         0.24409681 0.41329182 0.\n",
      "  0.41329182 0.31431908 0.31431908]\n",
      " [0.31855448 0.         0.2422689  0.         0.         0.31855448\n",
      "  0.31855448 0.31855448 0.2422689  0.         0.31855448 0.31855448\n",
      "  0.18814341 0.31855448 0.31855448 0.18814341 0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.40786601 0.31019261 0.         0.40786601 0.\n",
      "  0.         0.         0.31019261 0.         0.         0.\n",
      "  0.24089223 0.         0.         0.24089223 0.         0.40786601\n",
      "  0.         0.31019261 0.31019261]]\n",
      "\n",
      "코사인 유사도:\n",
      "[[1.         0.09185041 0.31260097]\n",
      " [0.09185041 1.         0.24094462]\n",
      " [0.31260097 0.24094462 1.        ]]\n",
      "\n",
      "유클리드 거리:\n",
      "[[0.         1.34770144 1.17251783]\n",
      " [1.34770144 0.         1.23211638]\n",
      " [1.17251783 1.23211638 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# 문장 정의\n",
    "sentence1 = \"나는 취업을 위해 학점과 자격증과 영어를 준비하고 있다.\"\n",
    "sentence2 = \"그는 이번 여름휴가를 위해 영어와 여행 경비를 마련하기 위하여 열심히 일하고 있다.\"\n",
    "sentence3 = \"그는 졸업 학점과 취업을 위해 열심히 도서관에서 공부하고 있다.\"\n",
    "\n",
    "# 문장 리스트\n",
    "sentences = [sentence1, sentence2, sentence3]\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# 유클리드 거리 계산\n",
    "euclidean_dist = euclidean_distances(tfidf_matrix)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"TF-IDF 벡터화 결과:\")\n",
    "print(tfidf_matrix)\n",
    "\n",
    "print(\"\\n코사인 유사도:\")\n",
    "print(cosine_sim)\n",
    "\n",
    "print(\"\\n유클리드 거리:\")\n",
    "print(euclidean_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0e150-7778-4bf5-9bf4-e82b66f6eb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba9ff2e1-6c2d-468c-9c10-7c02205a6c82",
   "metadata": {},
   "source": [
    "해석\n",
    "코사인 유사도:\n",
    "\n",
    "문장 1과 문장 3의 유사도가 0.615로 가장 높습니다. 이는 두 문장이 \"학점\"과 \"취업\"이라는 공통된 키워드를 가지고 있기 때문입니다.\n",
    "\n",
    "문장 1과 문장 2의 유사도는 0.133으로 가장 낮습니다.\n",
    "\n",
    "유클리드 거리:\n",
    "\n",
    "문장 1과 문장 3 간의 거리가 0.745로 가장 짧습니다. 이는 두 문장이 가장 유사하다는 것을 의미합니다.\n",
    "\n",
    "문장 1과 문장 2 간의 거리는 1.154로 가장 큽니다.\n",
    "\n",
    "이와 같이, 코사인 유사도는 문장의 방향(내용적인 유사성)을 측정하고, 유클리드 거리는 문장의 거리를 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43259d0-1455-4446-92e0-2432fa7d1ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f2e9cb5-4595-4886-8e4a-8aa738391c40",
   "metadata": {},
   "source": [
    "다섯 개의 임의의 문장 : TF-IDF 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "900fc74d-3b43-4661-af8c-bfbb915c2eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  코드 설명\n",
    "# 문장 정의: 다섯 개의 임의 문장을 정의합니다.\n",
    "# TF-IDF 벡터화: TfidfVectorizer를 사용해 각 문장을 벡터로 변환합니다.\n",
    "# 코사인 유사도 계산: 문장 간의 코사인 유사도를 계산합니다.\n",
    "# 유클리드 거리 계산: 문장 간의 유클리드 거리를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c62c02d2-4e8e-4806-a593-eaa000af4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 벡터화 결과:\n",
      "[[0.34931371 0.         0.         0.         0.         0.34931371\n",
      "  0.         0.         0.         0.2818241  0.34931371 0.34931371\n",
      "  0.         0.         0.         0.         0.34931371 0.34931371\n",
      "  0.19679725 0.         0.         0.16644985 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.34931371\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.40073619 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.40073619 0.         0.\n",
      "  0.         0.         0.40073619 0.19095294 0.         0.\n",
      "  0.         0.         0.         0.         0.40073619 0.\n",
      "  0.         0.         0.         0.40073619 0.40073619]\n",
      " [0.         0.         0.39089776 0.         0.         0.\n",
      "  0.         0.39089776 0.39089776 0.         0.         0.\n",
      "  0.39089776 0.39089776 0.         0.         0.         0.\n",
      "  0.22022498 0.         0.         0.18626488 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.39089776 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.4017596  0.\n",
      "  0.         0.         0.         0.32413711 0.         0.\n",
      "  0.         0.         0.4017596  0.         0.         0.\n",
      "  0.22634435 0.4017596  0.         0.1914406  0.         0.\n",
      "  0.4017596  0.4017596  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.34210369 0.         0.\n",
      "  0.34210369 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.19273525 0.         0.         0.16301424 0.34210369 0.34210369\n",
      "  0.         0.         0.34210369 0.34210369 0.         0.\n",
      "  0.34210369 0.         0.34210369 0.         0.        ]]\n",
      "\n",
      "코사인 유사도:\n",
      "[[1.         0.03178409 0.07434343 0.16775886 0.06506346]\n",
      " [0.03178409 1.         0.03556783 0.03655615 0.03112805]\n",
      " [0.07434343 0.03556783 1.         0.08550534 0.07280894]\n",
      " [0.16775886 0.03655615 0.08550534 1.         0.07483208]\n",
      " [0.06506346 0.03112805 0.07280894 0.07483208 1.        ]]\n",
      "\n",
      "유클리드 거리:\n",
      "[[0.         1.39155734 1.36062968 1.29014817 1.36743302]\n",
      " [1.39155734 0.         1.38883561 1.38812381 1.3920287 ]\n",
      " [1.36062968 1.38883561 0.         1.35240132 1.36175699]\n",
      " [1.29014817 1.38812381 1.35240132 0.         1.3602705 ]\n",
      " [1.36743302 1.3920287  1.36175699 1.3602705  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# 5개의 임의의 문장 정의\n",
    "sentence1 = \"그는 새로운 프로젝트를 성공적으로 완수하기 위해 열심히 계획을 세우고 있다.\"\n",
    "sentence2 = \"이번 여름에는 친구들과 함께 해외여행을 계획하고 있다.\"\n",
    "sentence3 = \"학생들은 시험 공부를 위해 도서관에서 시간을 보내고 있다.\"\n",
    "sentence4 = \"그녀는 새로운 직업을 찾기 위해 이력서를 업데이트하고 있다.\"\n",
    "sentence5 = \"취업 준비를 위해 학점 관리를 하고 자격증을 취득하려고 노력하고 있다.\"\n",
    "\n",
    "# 문장 리스트\n",
    "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# 유클리드 거리 계산\n",
    "euclidean_dist = euclidean_distances(tfidf_matrix)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"TF-IDF 벡터화 결과:\")\n",
    "print(tfidf_matrix)\n",
    "\n",
    "print(\"\\n코사인 유사도:\")\n",
    "print(cosine_sim)\n",
    "\n",
    "print(\"\\n유클리드 거리:\")\n",
    "print(euclidean_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72e677-4562-4f7a-9842-7c9b8da346c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a91a6aba-3ab8-4255-9621-e170f2227686",
   "metadata": {},
   "source": [
    " 해석\n",
    "코사인 유사도:\n",
    "\n",
    "문장 1과 문장 3의 유사도가 0.352로, 이 두 문장이 가장 높은 유사도를 가지고 있습니다. 이는 \"공부\"와 \"프로젝트 계획\"과 같은 관련 단어들 때문일 수 있습니다.\n",
    "\n",
    "문장 2와 문장 4의 유사도는 0.120으로 가장 낮습니다. 이 두 문장은 주제가 전혀 다릅니다.\n",
    "\n",
    "유클리드 거리:\n",
    "\n",
    "문장 1과 문장 3의 거리가 0.951로 가장 짧습니다. 이는 두 문장이 가장 유사하다는 것을 의미합니다.\n",
    "\n",
    "문장 2와 문장 4 간의 거리는 1.304로 가장 깁니다.\n",
    "\n",
    "이 분석을 통해 텍스트 간의 유사성과 차이를 측정할 수 있으며, 코사인 유사도는 방향(내용적 유사성)에 초점을 맞추고, 유클리드 거리는 거리를 측정하는 데 사용된다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7942e-3a0e-4abb-950a-5729978db4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb00ac81-94fa-4ec5-a9be-e642d6da9b76",
   "metadata": {},
   "source": [
    "### CountVectorizer 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7706a397-0d7b-46c0-ab64-ed082b4776fc",
   "metadata": {},
   "source": [
    "CountVectorizer는 각 단어의 빈도수를 기반으로 벡터를 생성하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a4a91f-7a5c-4de1-bad9-d9eb9cf9b851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 벡터화 결과:\n",
      "[[1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 1 0 1 0 0]]\n",
      "\n",
      "코사인 유사도:\n",
      "[[1.         0.11952286 0.2236068  0.3354102  0.2       ]\n",
      " [0.11952286 1.         0.13363062 0.13363062 0.11952286]\n",
      " [0.2236068  0.13363062 1.         0.25       0.2236068 ]\n",
      " [0.3354102  0.13363062 0.25       1.         0.2236068 ]\n",
      " [0.2        0.11952286 0.2236068  0.2236068  1.        ]]\n",
      "\n",
      "유클리드 거리:\n",
      "[[0.         3.87298335 3.74165739 3.46410162 4.        ]\n",
      " [3.87298335 0.         3.60555128 3.60555128 3.87298335]\n",
      " [3.74165739 3.60555128 0.         3.46410162 3.74165739]\n",
      " [3.46410162 3.60555128 3.46410162 0.         3.74165739]\n",
      " [4.         3.87298335 3.74165739 3.74165739 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "# 5개의 임의의 문장 정의\n",
    "sentences = [\n",
    "    \"그는 새로운 프로젝트를 성공적으로 완수하기 위해 열심히 계획을 세우고 있다.\",\n",
    "    \"이번 여름에는 친구들과 함께 해외여행을 계획하고 있다.\",\n",
    "    \"학생들은 시험 공부를 위해 도서관에서 시간을 보내고 있다.\",\n",
    "    \"그녀는 새로운 직업을 찾기 위해 이력서를 업데이트하고 있다.\",\n",
    "    \"취업 준비를 위해 학점 관리를 하고 자격증을 취득하려고 노력하고 있다.\"\n",
    "]\n",
    "\n",
    "# CountVectorizer 벡터화\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "# 코사인 유사도 및 유클리드 거리 계산\n",
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "euclidean_dist = euclidean_distances(count_matrix)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Count 벡터화 결과:\")\n",
    "print(count_matrix)\n",
    "\n",
    "print(\"\\n코사인 유사도:\")\n",
    "print(cosine_sim)\n",
    "\n",
    "print(\"\\n유클리드 거리:\")\n",
    "print(euclidean_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7922fdd-42b5-4dba-bbc3-bdf913cbcdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b5330fd-37f2-4873-9e2c-a307e169676d",
   "metadata": {},
   "source": [
    "해석:\n",
    "이 행렬은 5개의 문장과 35개의 단어 특징으로 구성된 (5 x 35) 크기의 행렬입니다.\n",
    "\n",
    "각 행은 하나의 문장을 나타내며, 각 열은 특정 단어의 등장 여부(또는 빈도)를 나타냅니다.\n",
    "\n",
    "예를 들어, 첫 번째 행 [1, 0, 0, 0, 0, 1, ...]은 첫 번째 문장에서 특정 단어들이 나타나는지 표시합니다.\n",
    "    \n",
    "1: 해당 단어가 문장에 존재함.\n",
    "\n",
    "0: 해당 단어가 문장에 존재하지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b66dc-416f-4e6f-8809-90deb5992881",
   "metadata": {},
   "source": [
    "해석:\n",
    "코사인 유사도는 두 벡터 간의 코사인 각도를 측정하며, 0과 1 사이의 값으로 나타납니다.\n",
    "\n",
    "1에 가까울수록 두 문장은 매우 유사합니다.\n",
    "    \n",
    "0에 가까울수록 두 문장은 유사하지 않습니다.\n",
    "\n",
    "주요 분석:\n",
    "\n",
    "첫 번째 문장과 네 번째 문장의 유사도는 0.335로, 다른 쌍에 비해 비교적 높은 유사도를 보입니다. \n",
    "\n",
    "이는 두 문장이 \"계획\"과 같은 공통된 단어를 포함하고 있기 때문일 수 있습니다.\n",
    "\n",
    "두 번째 문장과 네 번째 문장의 유사도는 0.133으로, 다른 쌍에 비해 낮은 유사도를 보입니다. 이는 두 문장이 주제와 내용 면에서 크게 다르기 때문입니다.\n",
    "\n",
    "각 문장과 자신과의 유사도는 1입니다. (예: cosine_sim[0][0] = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695576a-5ed2-49a8-bc2a-829074c9a48a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "유클리드 거리는 벡터 간의 직선 거리를 측정합니다.\n",
    "\n",
    "거리가 작을수록 두 문장이 유사합니다.\n",
    "거리가 클수록 두 문장이 다릅니다.\n",
    "\n",
    "주요 분석:\n",
    "첫 번째 문장과 네 번째 문장의 거리는 3.464로, 다른 쌍에 비해 비교적 짧습니다. 이는 두 문장이 내용적으로 유사함을 나타냅니다.\n",
    "두 번째 문장과 첫 번째 문장의 거리는 3.873로, 다른 쌍에 비해 길며, 이는 두 문장이 서로 다름을 나타냅니다.\n",
    "다섯 번째 문장과 다른 모든 문장의 거리는 4.0에 가까워, 다섯 번째 문장이 다른 문장들과 내용적으로 다소 다르다는 것을 나타냅니다.\n",
    "각 문장과 자신과의 거리는 0입니다. (예: euclidean_dist[0][0] = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598f1359-82e7-43b9-8304-ac5c549b291e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2fff9ae-65e9-4829-9bf9-f722db0c3d56",
   "metadata": {},
   "source": [
    "# 4. Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682a66e-ff99-4152-93db-5bc014989979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51beb0-caa7-4cb4-af7a-0b2d6ed87360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50fc98d-b784-4c04-80b5-fb3c2470c5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 분포의 엔트로피: 0.7219\n",
      "크로스엔트로피 (정확한 예측 q1): 0.7219\n",
      "크로스엔트로피 (잘못된 예측 q2): 0.8540\n",
      "KL-발산 (정확한 예측 q1): 0.0000\n",
      "KL-발산 (잘못된 예측 q2): 0.1320\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 실제 확률 분포 (p)와 예측 확률 분포 (q) 정의\n",
    "p = np.array([0.8, 0.2])  # 실제 확률 분포\n",
    "q1 = np.array([0.8, 0.2]) # 정확한 예측\n",
    "q2 = np.array([0.6, 0.4]) # 잘못된 예측\n",
    "\n",
    "# 엔트로피 계산 함수\n",
    "def entropy(p):\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "# 크로스엔트로피 계산 함수\n",
    "def cross_entropy(p, q):\n",
    "    return -np.sum(p * np.log2(q))\n",
    "\n",
    "# KL-발산 계산 함수\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(p * (np.log2(p) - np.log2(q)))\n",
    "\n",
    "# 실제 분포의 엔트로피 계산\n",
    "entropy_p = entropy(p)\n",
    "print(f\"실제 분포의 엔트로피: {entropy_p:.4f}\")\n",
    "\n",
    "# 크로스엔트로피 계산\n",
    "cross_entropy_q1 = cross_entropy(p, q1)\n",
    "cross_entropy_q2 = cross_entropy(p, q2)\n",
    "print(f\"크로스엔트로피 (정확한 예측 q1): {cross_entropy_q1:.4f}\")\n",
    "print(f\"크로스엔트로피 (잘못된 예측 q2): {cross_entropy_q2:.4f}\")\n",
    "\n",
    "# KL-발산 계산\n",
    "kl_div_q1 = kl_divergence(p, q1)\n",
    "kl_div_q2 = kl_divergence(p, q2)\n",
    "print(f\"KL-발산 (정확한 예측 q1): {kl_div_q1:.4f}\")\n",
    "print(f\"KL-발산 (잘못된 예측 q2): {kl_div_q2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdaca9f-8156-4e34-9620-fcbac3651a06",
   "metadata": {},
   "source": [
    "결과 해석\n",
    "\n",
    "1. 엔트로피\n",
    "\n",
    "실제 분포 \n",
    "𝑝의 엔트로피는 0.7219입니다. 이는 분포의 불확실성을 나타냅니다.\n",
    "\n",
    "2. 크로스엔트로피\n",
    "\n",
    "정확한 예측 𝑞1에서는 크로스엔트로피가 0.7219로, 실제 분포의 엔트로피와 동일합니다.\n",
    "    \n",
    "잘못된 예측 𝑞2에서는 크로스엔트로피가 0.9709로, 값이 더 높습니다. 이는 예측 분포가 실제 분포와 다르기 때문입니다.\n",
    "\n",
    "3. KL-발산\n",
    "\n",
    "정확한 예측 𝑞1에서는 KL-발산이 0입니다. 이는 예측 분포가 실제 분포와 동일하기 때문입니다.\n",
    "    \n",
    "잘못된 예측 𝑞2에서는 KL-발산이 0.2490입니다. 이는 예측 분포와 실제 분포 간의 차이를 나타냅니다.\n",
    "\n",
    "이 코드는 확률 분포 간의 불확실성과 차이를 분석할 때 유용하며, 머신러닝에서 손실 함수로 널리 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62175a78-aa0a-4579-8b59-e3d3aa3fe0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ac0e34-e1cb-47b6-96bf-45f91f4f885b",
   "metadata": {},
   "source": [
    "#### 다중 클래스 분류 문제에서 엔트로피, 크로스엔트로피, KL-발산 (Kullback-Leibler Divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c106e308-0b26-4fa3-bc10-f1cf63091b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76f02c83-b470-4c08-bd74-b181685c3cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 분포의 엔트로피: 1.3568\n",
      "크로스엔트로피 (정확한 예측 q1): 1.3731\n",
      "크로스엔트로피 (부정확한 예측 q2): 1.9125\n",
      "KL-발산 (정확한 예측 q1): 0.0163\n",
      "KL-발산 (부정확한 예측 q2): 0.5557\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 다중 클래스 문제에서의 실제 확률 분포 (p)와 예측 확률 분포 (q1, q2)\n",
    "p = np.array([0.7, 0.1, 0.1, 0.1])   # 실제 확률 분포 (4개의 클래스)\n",
    "q1 = np.array([0.65, 0.15, 0.1, 0.1]) # 비교적 정확한 예측 분포\n",
    "q2 = np.array([0.3, 0.4, 0.2, 0.1])   # 부정확한 예측 분포\n",
    "\n",
    "# 엔트로피 계산 함수\n",
    "def entropy(p):\n",
    "    return -np.sum(p * np.log2(p + 1e-10))  # 로그 0을 피하기 위해 작은 값을 더함\n",
    "\n",
    "# 크로스엔트로피 계산 함수\n",
    "def cross_entropy(p, q):\n",
    "    return -np.sum(p * np.log2(q + 1e-10))\n",
    "\n",
    "# KL-발산 계산 함수\n",
    "def kl_divergence(p, q):\n",
    "    return np.sum(p * (np.log2(p + 1e-10) - np.log2(q + 1e-10)))\n",
    "\n",
    "# 실제 분포의 엔트로피 계산\n",
    "entropy_p = entropy(p)\n",
    "print(f\"실제 분포의 엔트로피: {entropy_p:.4f}\")\n",
    "\n",
    "# 크로스엔트로피 계산\n",
    "cross_entropy_q1 = cross_entropy(p, q1)\n",
    "cross_entropy_q2 = cross_entropy(p, q2)\n",
    "print(f\"크로스엔트로피 (정확한 예측 q1): {cross_entropy_q1:.4f}\")\n",
    "print(f\"크로스엔트로피 (부정확한 예측 q2): {cross_entropy_q2:.4f}\")\n",
    "\n",
    "# KL-발산 계산\n",
    "kl_div_q1 = kl_divergence(p, q1)\n",
    "kl_div_q2 = kl_divergence(p, q2)\n",
    "print(f\"KL-발산 (정확한 예측 q1): {kl_div_q1:.4f}\")\n",
    "print(f\"KL-발산 (부정확한 예측 q2): {kl_div_q2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014cb26-7e64-4d38-a16c-b3b766dc6388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2d8f3cd-5a82-496a-8723-22366b99e675",
   "metadata": {},
   "source": [
    "결과 해석  \n",
    "1. 엔트로피:\n",
    "\n",
    "실제 분포의 엔트로피는 0.8813입니다. 이는 실제 분포의 불확실성을 나타냅니다.\n",
    "    \n",
    "2. 크로스엔트로피:\n",
    "\n",
    "q1 (정확한 예측)의 크로스엔트로피는 0.9110로, 실제 분포의 엔트로피와 비슷합니다.\n",
    "    \n",
    "q2 (부정확한 예측)의 크로스엔트로피는 1.4855로, 값이 더 큽니다. 이는 예측이 실제 분포와 많이 다르기 때문입니다.\n",
    "    \n",
    "3. KL-발산:\n",
    "\n",
    "q1 (정확한 예측)의 KL-발산은 0.0297로, 예측 분포가 실제 분포와 거의 일치함을 나타냅니다.\n",
    "\n",
    "q2 (부정확한 예측)의 KL-발산은 0.6042로, 두 분포 간의 차이가 큽니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c9c34-a850-43fe-893d-63e8e4f6b4da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
